# AI-Security-Resources

This Github repository summarizes a list of research papers on **AI security** from the four top academic conferences, namely 
IEEE Symposium on Security and Privacy (**S&P**), Network and Distributed System Security Symposium (**NDSS**), **USENIX Security** Symposium, and ACM Conference on Computer and Communications Security (**CCS**). 

*This repository is supported by the Trustworthy Artificial Intelligence ([T-AI](http://trustai.group)) Lab at  Huazhong University of Science and Technology (HUST).*

We will try our best to continuously maintain this Github Repository in a weekly manner.

## News
* 2023/7/25: Zhang Hangtao adds NDSS & USENIX Security papers.
* 2023/7/24: Zhou Ziqi adds S&P papers.
* 2023/7/23: We create the AI-Security-Resources repository.


## Table of Contents

- [Papers in S&P](#papers-in-sp)
  - [S&P'2024](#papers-in-sp24)
  - [S&P'2023](#papers-in-sp23)
  - [S&P'2022](#papers-in-sp22)
  - [S&P'2021](#papers-in-sp21)
- [Papers in NDSS](#papers-in-ndss)
  - [NDSS'2023](#NDSS'2023)
  - [NDSS'2022](#NDSS'2022)
  - [NDSS'2021](#NDSS'2021)
- [Papers in USENIX Security](#papers-in-usenix-security)
  - [USENIX Security'2023](#USENIX-Security'2023)
  - [USENIX Security'2022](#USENIX-Security'2022)
  - [USENIX Security'2021](#USENIX-Security'2021)
- [Papers in CCS](#papers-in-ccs)
  - [CCS'2023](#CCS'2023)
  - [CCS'2022](#CCS'2022)
  - [CCS'2021](#CCS'2021)
## Papers in S&P

### S&P'2024

- Why Does Little Robustness Help? A Further Step Towards Understanding Adversarial Transferability. **[Topic: AEs]**
  [[Code]](https://xxxxxxxx)[[pdf]](https://arxiv.org/pdf/2307.07873.pdf)
  - Yechao Zhang, Shengshan Hu, Leo Yu Zhang, Junyu Shi, Xiaogeng Liu, Minghui Li, Wei Wan, Hai Jin. *IEEE Symposium on Security and Privacy*, 2024.

### S&P'2023

### S&P'2022

- “Adversarial Examples” for Proof-of-Learning. **[Topic: AEs]**
  [[pdf]](https://arxiv.org/pdf/2108.09454.pdf)
  - Rui Zhang, Jian Liu, Yuan Ding, Zhibo Wang, Qingbiao Wu, and Kui Ren. *IEEE Symposium on Security and Privacy*, 2022.

- Transfer Attacks Revisited: A Large-Scale Empirical Study in Real Computer Vision Settings. **[Topic:AEs]**
  [[pdf]](https://arxiv.org/pdf/2204.04063.pdf)
  - Yuhao Mao, Chong Fu, Saizhuo Wang, Shouling Ji, Xuhong Zhang, Zhenguang Liu, Jun Zhou, Alex X.Liu, Raheem Beyah, Ting Wang. *IEEE Symposium on Security and Privacy*, 2022.

- Bad Characters: Imperceptible NLP Attacks. **[Topic: AEs]**
  [[Code]](https://github.com/nickboucher/imperceptible)[[pdf]](https://arxiv.org/pdf/2106.09898.pdf)
  - Nicholas Boucher, Ilia Shumailov, Ross Anderson, Nicolas Papernot. *IEEE Symposium on Security and Privacy*, 2022.

- Universal 3-Dimensional Perturbations for Black-Box Attacks on Video Recognition Systems. **[Topic: AEs]**
  [[pdf]](https://arxiv.org/pdf/2107.04284.pdf)
  - Shangyu Xie, Han Wang, Yu Kong, Yuan Hong. *IEEE Symposium on Security and Privacy*, 2022.

- BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervised Learning. **[Topic: Backdoor]**
  [[Code]](https://github.com/jinyuan-jia/BadEncoder)[[pdf]](https://arxiv.org/pdf/2108.00352.pdf)
  - Jinyuan Jia, Yupei Liu, Neil Zhenqiang Gong. *IEEE Symposium on Security and Privacy*, 2022.

- PICCOLO: Exposing Complex Backdoors in NLP Transformer Models. **[Topic: Backdoor]**
  [[pdf]](https://par.nsf.gov/servlets/purl/10335908)
  - Yingqi Liu, Guangyu Shen, Guanhong Tao, Shengwei An, Shiqing Ma, Xiangyu Zhang. *IEEE Symposium on Security and Privacy*, 2022.

- Membership Inference Attacks From First Principles. **[Topic: MIA]**
  [[pdf]](https://arxiv.org/pdf/2112.03570.pdf)
  - Nicholas Carlini, Steve Chien, Milad Nasr, Shuang Song, Andreas Terzis, Florian Tramer. *IEEE Symposium on Security and Privacy*, 2022.

- Back to the Drawing Board: A Critical Evaluation of Poisoning Attacks on Production Federated Learning. **[Topic: PA & FL]**
  [[pdf]](https://arxiv.org/pdf/2108.10241.pdf)
  - Virat Shejwalkar, Amir Houmansadr, Peter Kairouz, Daniel Ramage. *IEEE Symposium on Security and Privacy*, 2022.

- Model Stealing Attacks Against Inductive Graph Neural Networks. **[Topic: MSA & GNN]**
  [[pdf]](https://arxiv.org/pdf/2112.08331.pdf)
  - Yun Shen, Xinlei He, Yufei Han, Yang Zhang. *IEEE Symposium on Security and Privacy*, 2022.
 
- SoK: How Robust is Image Classification Deep Neural Network Watermarking? **[Topic: Watermark]**
  [[pdf]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9833693)
  - Nils Lukas, Edward Jiang, Xinda Li, Florian Kerschbaum. *IEEE Symposium on Security and Privacy*, 2022.


### S&P'2021

- Hear "No Evil", See "Kenansville": Efficient and Transferable Black-Box Attacks on Speech Recognition and Voice Identification Systems. **[Topic: AEs]**
  [[pdf]](https://arxiv.org/pdf/1910.05262.pdf)
  - Hadi Abdullah, Muhammad Sajidur Rahman, Washington Garcia, Logan Blue, Kevin Warren, Anurag Swarnim Yadav, Tom Shrimpton, Patrick Traynor. *IEEE Symposium on Security and Privacy*, 2021.

- SoK: The Faults in our ASRs: An Overview of Attacks against Automatic Speech Recognition and Speaker Identification Systems. **[Topic: AEs]**
[  [pdf]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9519395)
  - Hadi Abdullah, Kevin Warren, Vincent Bindschaedler, Nicolas Papernot, Patrick Traynor. *IEEE Symposium on Security and Privacy*, 2021.

- Invisible for both Camera and LiDAR: Security of Multi-Sensor Fusion based Perception in Autonomous Driving Under Physical-World Attacks. **[Topic: AEs]**
  [[pdf]](https://arxiv.org/pdf/2106.09249.pdf)
  - Yulong Cao, Ningfei Wang, Chaowei Xiao, Dawei Yang, Jin Fang, Ruigang Yang, Qi Alfred Chen, Mingyan Liu, Bo Li. *IEEE Symposium on Security and Privacy*, 2021.

- Who is Real Bob? Adversarial Attacks on Speaker Recognition Systems. **[Topic: AEs]**
  [[pdf]](https://arxiv.org/pdf/1911.01840.pdf)
  - Guangke Chen, Sen Chen, Lingling Fan, Xiaoning Du, Zhe Zhao, Fu Song, Yang Liu. *IEEE Symposium on Security and Privacy*, 2021.

- Adversarial Watermarking Transformer: Towards Tracing Text Provenance with Data Hiding. **[Topic: Watermark]**
  [[pdf]](https://arxiv.org/pdf/2009.03015.pdf)
  - Sahar Abdelnabi, Mario Fritz. *IEEE Symposium on Security and Privacy*, 2021.


## Papers in NDSS 

### NDSS'2023

- Fusion: Efficient and Secure Inference Resilient to Malicious Servers. **[Topic: MLaaS]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_s199_paper.pdf)
  - Caiqin Dong, Jian Weng, Jia-Nan Liu, Yue Zhang, Yao Tong, Anjia Yang, Yudan Cheng, Shun Hu. *Network and Distributed System Security*, 2023.

- Machine Unlearning of Features and Labels. **[Topic: Machine-Unlearning]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_s87_paper.pdf)
  - Alexander Warnecke, Lukas Pirch, Christian Wressnegger, Konrad Rieck. *Network and Distributed System Security*, 2023.

- PPA: Preference Profiling Attack Against Federated Learning. **[Topic: FL]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_s171_paper.pdf)
  - Chunyi Zhou, Yansong Gao, Anmin Fu, Kai Chen, Zhiyang Dai, Zhi Zhang, Minhui Xue, Yuqing Zhang. *Network and Distributed System Security*, 2023.

- RoVISQ: Reduction of Video Service Quality via Adversarial Attacks on Deep Learning-based Video Compression. **[Topic: AEs]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_s165_paper.pdf)
  - Jung-Woo Chang, Mojan Javaheripi, Seira Hidano, Farinaz Koushanfar. *Network and Distributed System Security*, 2023.

- Securing Federated Sensitive Topic Classification against Poisoning Attacks. **[Topic: FL]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_s112_paper.pdf)
  - Tianyue Chu, Alvaro Garcia-Recuero, Costas Iordanou, Georgios Smaragdakis, Nikolaos Laoutaris. *Network and Distributed System Security*, 2023.

- The “Beatrix” Resurrections: Robust Backdoor Detection via Gram Matrices. **[Topic: Backdoor]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_s69_paper.pdf)
  - Wanlun Ma, Derui Wang, Ruoxi Sun, Minhui Xue, Sheng Wen, Yang Xiang. *Network and Distributed System Security*, 2023.

- Adversarial Robustness for Tabular Data through Cost and Utility Awareness. **[Topic: AEs]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_f924_paper.pdf)
  - Klim Kireev, Bogdan Kulynych, Carmela Troncoso. *Network and Distributed System Security*, 2023. 

- Backdoor Attacks Against Dataset Distillation. **[Topic: Backdoor]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_f287_paper.pdf)
  - Yugeng Liu, Zheng Li, Michael Backes, Yun Shen, Yang Zhang. *Network and Distributed System Security*, 2023. 

- BEAGLE: Forensics of Deep Learning Backdoor Attack for Better Defense. **[Topic: Backdoor]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_f944_paper.pdf)
  - Siyuan Cheng, Guanhong Tao, Yingqi Liu, Shengwei An, Xiangzhe Xu, Shiwei Feng, Guangyu Shen, Kaiyuan Zhang, Qiuling Xu, Shiqing Ma, Xiangyu Zhang. *Network and Distributed System Security*, 2023. 

- Focusing on Pinocchio's Nose: A Gradients Scrutinizer to Thwart Split-Learning Hijacking Attacks Using Intrinsic Attributes. **[Topic: SL]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_f874_paper.pdf)
  - Jiayun Fu, Xiaojing Ma, Bin B. Zhu, Pingyi Hu, Ruixin Zhao, Yaru Jia, Peng Xu, Hai Jin, Dongmei Zhang. *Network and Distributed System Security*, 2023. 

- REaaS: Enabling Adversarially Robust Downstream Classifiers via Robust Encoder as a Service. **[Topic: AEs]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_f444_paper.pdf)
  - Wenjie Qu, Jinyuan Jia, Neil Zhenqiang Gong. *Network and Distributed System Security*, 2023. 

### NDSS'2022

- DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspection. **[Topic: Backdoor]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2022-156-paper.pdf)
  - Phillip Rieger, Thien Duc Nguyen, Markus Miettinen, Ahmad-Reza Sadeghi. *Network and Distributed System Security*, 2022. 

- FedCRI: Federated Mobile Cyber-Risk Intelligence. **[Topic: FL]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2022-153-paper.pdf)
  - Hossein Fereidooni, Alexandra Dmitrienko, Phillip Rieger, Markus Miettinen, Ahmad-Reza Sadeghi, Felix Madlener. *Network and Distributed System Security*, 2022. 

- Get a Model! Model Hijacking Attack Against Machine Learning Models. **[Topic: Model-Hijacking]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2022-64-paper.pdf)
  - Ahmed Salem, Michael Backes, Yang Zhang. *Network and Distributed System Security*, 2022. 

- Local and Central Differential Privacy for Robustness and Privacy in Federated Learning. **[Topic: FL]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2022-54-paper.pdf)
  - Mohammad Naseri, Jamie Hayes, Emiliano De Cristofaro. *Network and Distributed System Security*, 2022. 

- Property Inference Attacks Against GANs. **[Topic: IA & GAN]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2022-19-paper.pdf)
  - Junhao Zhou, Yufei Chen, Chao Shen, Yang Zhang. *Network and Distributed System Security*, 2022. 

- ATTEQ-NN: Attention-based QoE-aware Evasive Backdoor Attacks. **[Topic: Backdoor]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2022-12-paper.pdf)
  - Xueluan Gong, Yanjiao Chen, Jianshuo Dong, Qian Wang. *Network and Distributed System Security*, 2022. 

- Fooling the Eyes of Autonomous Vehicles: Robust Physical Adversarial Examples Against Traffic Sign Recognition Systems. **[Topic: AEs]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2022-130-paper.pdf)
  - Wei Jia, Zhaojun Lu, Haichun Zhang, Zhenglin Liu, Jie Wang, Gang Qu. *Network and Distributed System Security*, 2022. 

- MIRROR: Model Inversion for Deep Learning Network with High Fidelity. **[Topic: MIA]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2022-335-paper.pdf)
  - Shengwei An, Guanhong Tao, Qiuling Xu, Yingqi Liu, Guangyu Shen, Yuan Yao, Jingwei Xu, Xiangyu Zhang. *Network and Distributed System Security*, 2022. 

- RamBoAttack: A Robust and Query Efficient Deep Neural Network Decision Exploit. **[Topic: AEs]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2022-200-paper.pdf)
  - Viet Quoc Vo, Ehsan Abbasnejad, Damith C. Ranasinghe. *Network and Distributed System Security*, 2022. 


### NDSS'2021

- Data Poisoning Attacks to Deep Learning Based Recommender Systems. **[Topic: PAs]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/ndss2021_6C-4_24525_paper.pdf)
  - Hai Huang, Jiaming Mu, Neil Zhenqiang Gong, Qi Li, Bin Liu, Mingwei Xu. *Network and Distributed System Security*, 2021. 

- FLTrust: Byzantine-robust Federated Learning via Trust Bootstrapping. **[Topic: PA & FL]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/ndss2021_6C-2_24434_paper.pdf)
  - Xiaoyu Cao, Minghong Fang, Jia Liu, Neil Zhenqiang Gong. *Network and Distributed System Security*, 2021. 

- Manipulating the Byzantine: Optimizing Model Poisoning Attacks and Defenses for Federated Learning. **[Topic: PA & FL]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/ndss2021_6C-3_24498_paper.pdf)
  - Virat Shejwalkar, Amir Houmansadr. *Network and Distributed System Security*, 2021. 

- Practical Blind Membership Inference Attack via Differential Comparisons. **[Topic: MIA]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/ndss2021_5C-2_24293_paper.pdf)
  - Bo Hui, Yuchen Yang, Haolin Yuan, Philippe Burlina, Neil Zhenqiang Gong, Yinzhi Cao. *Network and Distributed System Security*, 2021. 

- POSEIDON: Privacy-Preserving Federated Neural Network Learning. **[Topic: FL]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/ndss2021_6C-1_24119_paper.pdf)
  - Sinem Sav, Apostolos Pyrgelis, Juan Ramón Troncoso-Pastoriza, David Froelicher, Jean-Philippe Bossuat, Joao Sa Sousa, Jean-Pierre Hubaux. *Network and Distributed System Security*, 2021.

## Papers in USENIX Security 

### USENIX Security '2023

- “Security is not my field, I’m a stats guy”: A Qualitative Root Cause Analysis of Barriers to Adversarial Machine Learning Defenses in Industry. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-324-mink.pdf)
  - Jaron Mink, Harjot Kaur, Juliane Schmüser and Sascha Fahl, Yasemin Acar. *USENIX Security*, 2023. 

- A Data-free Backdoor Injection Approach in Neural Networks. **[Topic: Backdoor]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-573-lv.pdf)
  - Peizhuo Lv, Chang Yue, Ruigang Liang, Yunfei Yang. *USENIX Security*, 2023. 

- A Plot is Worth a Thousand Words: Model Information Stealing Attacks via Scientific Plots. **[Topic: MSA]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-28-zhang-boyang.pdf)
  - Boyang Zhang, Xinlei He, Yun Shen, Tianhao Wang, Yang Zhang. *USENIX Security*, 2023. 

- Aegis: Mitigating Targeted Bit-flip Attacks against Deep Neural Networks. **[Topic: BFA]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-246-wang-jialai.pdf)
  - Jialai Wang, Ziyuan Zhang, Meiqi Wang, Han Qiu, Tianwei Zhang, Qi Li, Zongpeng Li, Tao Wei, Chao Zhang. *USENIX Security*, 2023. 

- Black-box Adversarial Example Attack towards FCG Based Android Malware Detection under Incomplete Feature Information. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-2-li-heng.pdf)
  - Heng Li, Zhang Cheng, Bang Wu, Liheng Yuan, Cuiying Gao, Wei Yuan, Xiapu Luo. *USENIX Security*, 2023. 

- CAPatch: Physical Adversarial Patch against Image Captioning Systems. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-121-zhang-shibo.pdf)
  - Shibo Zhang, Yushi Cheng, Wenjun Zhu, Xiaoyu Ji, Wenyuan Xu. *USENIX Security*, 2023. 

- DiffSmooth: Certifiably Robust Learning via Diffusion Models and Local Smoothing. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-540-zhang-jiawei.pdf)
  - Jiawei Zhang, Zhongzhu Chen, Huan Zhang, Chaowei Xiao, Bo Li. *USENIX Security*, 2023.

- Every Vote Counts: Ranking-Based Training of Federated Learning to Resist Poisoning Attacks. **[Topic: PA & FL]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-475-mozaffari.pdf)
  - Hamid Mozaffari, Virat Shejwalkar, Amir Houmansadr. *USENIX Security*, 2023. 

- Exorcising "Wraith": Protecting LiDAR-based Object Detector in Automated Driving System from Appearing Attacks. **[Topic: Appearing-Attack]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-190-xiao-qifan.pdf)
  - Qifan Xiao, Xudong Pan, Yifan Lu, Mi Zhang, Jiarun Dai, Min Yang. *USENIX Security*, 2023.  

- Fine-grained Poisoning Attack to Local Differential Privacy Protocols for Mean and Variance Estimation. **[Topic: DP]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-421-li-xiaoguang.pdf)
  - Xiaoguang Li, Ninghui Li, Wenhai Sun,  Neil Zhenqiang Gong, Hui Li. *USENIX Security*, 2023. 

- FreeEagle: Detecting Complex Neural Trojans in Data-Free Cases. **[Topic: Backdoor]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-85-fu-chong.pdf)
  - Chong Fu, Xuhong Zhang, Shouling Ji, Ting Wang, Peng Lin, Yanghe Feng, Jianwei Yin. *USENIX Security*, 2023. 

- GAP: Differentially Private Graph Neural Networks with Aggregation Perturbation. **[Topic: DP & GNN]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-196-sajadmanesh.pdf)
  - Sina Sajadmanesh, Ali Shahin Shamsabadi, Aurélien Bellet, Daniel Gatica-Perez. *USENIX Security*, 2023. 

- Lost at C: A User Study on the Security Implications of Large Language Model Code Assistants. **[Topic: LLM]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-353-sandoval.pdf)
  - Gustavo Sandoval, Hammond Pearce, Teo Nys, Ramesh Karri, Siddharth Garg, Brendan Dolan-Gavitt. *USENIX Security*, 2023. 

- Meta-Sift: How to Sift Out a Clean Subset in the Presence of Data Poisoning?. **[Topic: PA]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-99-zeng-yi.pdf)
  - Yi Zeng, Minzhou Pan, Himanshu Jahagirdar, Ming Jin, Lingjuan Lyu, Ruoxi Jia. *USENIX Security*, 2023. 

- No more Reviewer #2: Subverting Automatic Paper-Reviewer Assignment using Adversarial Learning. **[Topic: AEs]**
  [[pdf]](https://arxiv.org/pdf/2303.14443.pdf)
  - Thorsten Eisenhofer, Erwin Quiring, Jonas Möller, Doreen Riepel, Thorsten Holz, Konrad Rieck. *USENIX Security*, 2023. 

- PELICAN: Exploiting Backdoors of Naturally Trained Deep Learning Models In Binary Code Analysis. **[Topic: Backdoor]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-493-zhang-zhuo.pdf)
  - Zhuo Zhang, Guanhong Tao, Guangyu Shen, Shengwei An, Qiuling Xu, Yingqi Liu, Yapeng Ye, Yaoxuan Wu, Xiangyu Zhang. *USENIX Security*, 2023. 

- PrivateFL: Accurate, Differentially Private Federated Learning via Personalized Data Transformation. **[Topic: DP & FL]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-427-yang-yuchen.pdf)
  - Yuchen Yang, Bo Hui, Haolin Yuan, Neil Gong, Yinzhi Cao. *USENIX Security*, 2023. 

- Rethinking White-Box Watermarks on Deep Learning Models under Neural Structural Obfuscation. **[Topic: Watermark]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-444-yan-yifan.pdf)
  - Yifan Yan, Xudong Pan, Mi Zhang, and Min Yang. *USENIX Security*, 2023. 

- X-Adv: Physical Adversarial Object Attacks against X-ray Prohibited Item Detection. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-34-liu-aishan.pdf)
  - Aishan Liu, Jun Guo, Jiakai Wang, Siyuan Liang, Renshuai Tao, Wenbo Zhou, Cong Liu, Xianglong Liu. *USENIX Security*, 2023. 

- TPatch: A Triggered Physical Adversarial Patch. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_123-zhu-prepub.pdf)
  - Wenjun Zhu, Xiaoyu Ji, Yushi Cheng, Shibo Zhang, Wenyuan Xu. *USENIX Security*, 2023.  

- UnGANable: Defending Against GAN-based Face Manipulation. **[Topic: Deepfake]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_136-li_zheng-prepub.pdf)
  - WZheng Li, Ning Yu, Ahmed Salem, Michael Backes, Mario Fritz, Yang Zhang. *USENIX Security*, 2023. 

- Squint Hard Enough: Attacking Perceptual Hashing with Adversarial Machine Learning. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_146-prokos-prepub.pdf)
  - Jonathan Prokos, Neil Fendley, Matthew Green, Roei Schuster, Eran Tromer, Tushar Jois, Yinzhi Cao. *USENIX Security*, 2023. 

- The Space of Adversarial Strategies. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_256-sheatsley-prepub.pdf)
  - Ryan Sheatsley, Blaine Hoak, Eric Pauley, Patrick McDaniel. *USENIX Security*, 2023. 

- That Person Moves Like A Car: Misclassification Attack Detection for Autonomous Systems Using Spatiotemporal Consistency. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_278-man-prepub.pdf)
  - Yanmao Man, Raymond Muller, Ming Li, Z. Berkay Celik, Ryan Gerdes. *USENIX Security*, 2023. 

- NeuroPots: Realtime Proactive Defense against Bit-Flip Attacks in Neural Networks. **[Topic: BFA]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_334-liu_qi-prepub.pdf)
  - Qi Liu, Jieming Yin, Wujie Wen, Chengmo Yang, Shi Sha. *USENIX Security*, 2023. 

- URET: Universal Robustness Evaluation Toolkit (for Evasion). **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_347-eykholt-prepub.pdf)
  - Kevin Eykholt, Taesung Lee, Douglas Schales, Jiyong Jang, Ian Molloy, Masha Zorin. *USENIX Security*, 2023. 

- SMACK: Semantically Meaningful Adversarial Audio Attack. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_371-yu_zhiyuan-prepub.pdf)
  - Zhiyuan Yu, Yuanhaur Chang, Ning Zhang, Chaowei Xiao. *USENIX Security*, 2023. 

- Gradient Obfuscation Gives a False Sense of Security in Federated Learning. **[Topic: FL]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_372-yue-prepub.pdf)
  - Kai Yue, Richeng Jin, Chau-Wai Wong, Dror Baron, Huaiyu Dai. *USENIX Security*, 2023. 

- Fairness Properties of Face Recognition and Obfuscation Systems. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_388-rosenberg-prepub.pdf)
  - Harrison Rosenberg, Brian Tang, Kassem Fawaz, Somesh Jha. *USENIX Security*, 2023. 

- PCAT: Functionality and Data Stealing from Split Learning by Pseudo-Client Attack. **[Topic: SL]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_445-gao-prepub.pdf)
  - Xinben Gao, Lan Zhang. *USENIX Security*, 2023. 

### USENIX Security '2022

- ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine Learning Models. **[Topic: MIA]**
  [[pdf]](https://www.usenix.org/system/files/sec22-liu-yugeng.pdf)
  - Yugeng Liu, Rui Wen, Xinlei He, Ahmed Salem, Zhikun Zhang, Michael Backes, Emiliano De Cristofaro, Mario Fritz, Yang Zhang. *USENIX Security*, 2022. 

- Blacklight: Scalable Defense for Neural Networks against Query-Based Black-Box Attacks. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec22-li-huiying.pdf)
  - Huiying Li, Shawn Shan, Emily Wenger, Jiayun Zhang, Haitao Zheng, Ben Y. Zhao. *USENIX Security*, 2022. 

- AutoDA: Automated Decision-based Iterative Adversarial Attacks. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec22-fu-qi.pdf)
  - Qi-An Fu, Yinpeng Dong, Hang Su, Jun Zhu, Chao Zhang. *USENIX Security*, 2022. 

- Poison Forensics: Traceback of Data Poisoning Attacks in Neural Networks. **[Topic: PA]**
  [[pdf]](https://www.usenix.org/system/files/sec22-shan.pdf)
  - Shawn Shan, Arjun Nitin Bhagoji, Haitao Zheng, Ben Y. Zhao. *USENIX Security*, 2022. 

- Teacher Model Fingerprinting Attacks Against Transfer Learning. **[Topic: Fingerprinting]**
  [[pdf]](https://www.usenix.org/system/files/sec22-chen-yufei.pdf)
  - Yufei Chen, Chao Shen, Cong Wang, Yang Zhang. *USENIX Security*, 2022. 

- Hidden Trigger Backdoor Attack on NLP Models via Linguistic Style Manipulation. **[Topic: Backdoor]**
  [[pdf]](https://www.usenix.org/system/files/sec22-pan-hidden.pdf)
  - Xudong Pan, Mi Zhang, Beina Sheng, Jiaming Zhu, Min Yang. *USENIX Security*, 2022. 

- PoisonedEncoder: Poisoning the Unlabeled Pre-training Data in Contrastive Learning. **[Topic: PA]**
  [[pdf]](https://www.usenix.org/system/files/sec22-liu-hongbin.pdf)
  - Hongbin Liu, Jinyuan Jia, Neil Zhenqiang Gong. *USENIX Security*, 2022. 

- Pool Inference Attacks on Local Differential Privacy: Quantifying the Privacy Guarantees of Apple's Count Mean Sketch in Practice. **[Topic: IA & DP]**
  [[pdf]](https://www.usenix.org/system/files/sec22-gadotti_1.pdf)
  - Andrea Gadotti, Florimond Houssiau, Meenatchi Sundaram Muthu Selva Annamalai, Yves-Alexandre de Montjoye. *USENIX Security*, 2022. 

- PatchCleanser: Certifiably Robust Defense against Adversarial Patches for Any Image Classifier. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec22-xiang.pdf)
  - Chong Xiang, Saeed Mahloujifar, Prateek Mittal. *USENIX Security*, 2022. 

- Exploring the Security Boundary of Data Reconstruction via Neuron Exclusivity Analysis. **[Topic: DRA]**
  [[pdf]](https://www.usenix.org/system/files/sec22-pan-exploring.pdf)
  - Xudong Pan, Mi Zhang, Yifan Yan, Jiaming Zhu, Min Yang. *USENIX Security*, 2022. 

- Poisoning Attacks to Local Differential Privacy Protocols for Key-Value Data. **[Topic: PA & DP]**
  [[pdf]](https://www.usenix.org/system/files/sec22-wu-yongji.pdf)
  - Yongji Wu, Xiaoyu Cao, Jinyuan Jia, Neil Zhenqiang Gong. *USENIX Security*, 2022. 

- Communication-Efficient Triangle Counting under Local Differential Privacy. **[Topic: DP]**
  [[pdf]](https://www.usenix.org/system/files/sec22-imola.pdf)
  - Jacob Imola, Takao Murakami, Kamalika Chaudhuri. *USENIX Security*, 2022. 

- Security Analysis of Camera-LiDAR Fusion Against Black-Box Attacks on Autonomous Vehicles. **[Topic: AEs & AV]**
  [[pdf]](https://www.usenix.org/system/files/sec22-hallyburton.pdf)
  - R. Spencer Hallyburton, Yupei Liu, Yulong Cao, Z. Morley Mao, Miroslav Pajic. *USENIX Security*, 2022. 

- Transferring Adversarial Robustness Through Robust Representation Matching. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec22-vaishnavi.pdf)
  - Pratik Vaishnavi, Kevin Eykholt, Amir Rahmati. *USENIX Security*, 2022. 

- Seeing is Living? Rethinking the Security of Facial Liveness Verification in the Deepfake Era. **[Topic: Deepfake]**
  [[pdf]](https://www.usenix.org/system/files/sec22-li-changjiang.pdf)
  - Changjiang Li, Li Wang, Shouling Ji, Xuhong Zhang, Zhaohan Xi, Shanqing Guo, Ting Wang. *USENIX Security*, 2022. 

- On the Necessity of Auditable Algorithmic Definitions for Machine Unlearning. **[Topic: Machine-Unlearning]**
  [[pdf]](https://www.usenix.org/system/files/sec22-thudi.pdf)
  - Anvith Thudi, Hengrui Jia, Ilia Shumailov, Nicolas Papernot. *USENIX Security*, 2022. 

- Mitigating Membership Inference Attacks by Self-Distillation Through a Novel Ensemble Architecture. **[Topic: MIA]**
  [[pdf]](https://www.usenix.org/system/files/sec22-tang.pdf)
  - Xinyu Tang, Saeed Mahloujifar, Liwei Song, Virat Shejwalkar, Milad Nasr, Amir Houmansadr, Prateek Mittal. *USENIX Security*, 2022. 

- Membership Inference Attacks and Defenses in Neural Network Pruning. **[Topic: MIA]**
  [[pdf]](https://www.usenix.org/system/files/sec22-yuan-xiaoyong.pdf)
  - Xiaoyong Yuan, Lan Zhang. *USENIX Security*, 2022. 

- Efficient Differentially Private Secure Aggregation for Federated Learning via Hardness of Learning with Errors. **[Topic: DP & FL]**
  [[pdf]](https://www.usenix.org/system/files/sec22-stevens.pdf)
  - Timothy Stevens, Christian Skalka, Christelle Vincent, John Ring, Samuel Clark, Joseph Near. *USENIX Security*, 2022. 

- Who Are You (I Really Wanna Know)? Detecting Audio DeepFakes Through Vocal Tract Reconstruction. **[Topic: Deepfake]**
  [[pdf]](https://www.usenix.org/system/files/sec22-blue.pdf)
  - Logan Blue, Kevin Warren, Hadi Abdullah, Cassidy Gibson, Luis Vargas, Jessica O'Dell, Kevin Butler, Patrick Traynor. *USENIX Security*, 2022. 


- Are Your Sensitive Attributes Private? Novel Model Inversion Attribute Inference Attacks on Classification Models. **[Topic: MIAI]**
  [[pdf]](hhttps://www.usenix.org/system/files/sec22-mehnaz.pdf)
  - Shagufta Mehnaz, Sayanton V. Dibbo, Ehsanul Kabir, Ninghui Li, Elisa Bertino. *USENIX Security*, 2022. 

- FLAME: Taming Backdoors in Federated Learning. **[Topic: FL & Backdoor]**
  [[pdf]](https://www.usenix.org/system/files/sec22-nguyen.pdf)
  - Thien Duc Nguyen, Phillip Rieger, Huili Chen, Hossein Yalame, Helen Möllering, Hossein Fereidooni, Samuel Marchal, Markus Miettinen, Azalia Mirhoseini, Shaza Zeitouni, Farinaz Koushanfar, Ahmad-Reza Sadeghi, Thomas Schneider. *USENIX Security*, 2022. 

- Synthetic Data – Anonymisation Groundhog Day. **[Topic: Synthetic-Data]**
  [[pdf]](https://www.usenix.org/system/files/sec22-stadler.pdf)
  - Theresa Stadler, Bristena Oprisanu, Carmela Troncoso. *USENIX Security*, 2022. 

- On the Security Risks of AutoML. **[Topic: NAS]**
  [[pdf]](https://www.usenix.org/system/files/sec22-pang-ren.pdf)
  - Ren Pang, Zhaohan Xi, Shouling Ji, Xiapu Luo, Ting Wang. *USENIX Security*, 2022. 

- Inference Attacks Against Graph Neural Networks. **[Topic: IA & GNN]**
  [[pdf]](https://www.usenix.org/system/files/sec22-zhang-zhikun.pdf)
  - Zhikun Zhang, Min Chen, Michael Backes, Yun Shen, Yang Zhang. *USENIX Security*, 2022. 

- Adversarial Detection Avoidance Attacks: Evaluating the robustness of perceptual hashing-based client-side scanning. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec22-jain.pdf)
  - Shubham Jain, Ana-Maria Crețu, Yves-Alexandre de Montjoye. *USENIX Security*, 2022. 

- Label Inference Attacks Against Vertical Federated Learning. **[Topic: IA & FL]**
  [[pdf]](https://www.usenix.org/system/files/sec22-fu-chong.pdf)
  - Chong Fu, Xuhong Zhang, Shouling Ji, Jinyin Chen, Jingzheng Wu, Shanqing Guo, Jun Zhou, Alex X. Liu, Ting Wang. *USENIX Security*, 2022. 

- Rolling Colors: Adversarial Laser Exploits against Traffic Light Recognition. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec22-yan.pdf)
  - Chen Yan, Zhijian Xu, Zhanyuan Yin, Xiaoyu Ji, Wenyuan Xu. *USENIX Security*, 2022. 


### USENIX Security '2021

- PatchGuard: A Provably Robust Defense against Adversarial Patches via Small Receptive Fields and Masking. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec21-xiang.pdf)
  - Chong Xiang, Arjun Nitin Bhagoji, Vikash Sehwag, Prateek Mittal. *USENIX Security*, 2021. 

- PrivSyn: Differentially Private Data Synthesis. **[Topic: DP]**
  [[pdf]](https://www.usenix.org/system/files/sec21-zhang-zhikun.pdf)
  - Zhikun Zhang, Tianhao Wang, Ninghui Li, Jean Honorio, Michael Backes, Shibo He, Jiming Chen, Yang Zhang. *USENIX Security*, 2021. 

- Muse: Secure Inference Resilient to Malicious Clients. **[Topic: IA]**
  [[pdf]](https://www.usenix.org/system/files/sec21-lehmkuhl.pdf)
  - Ryan Lehmkuhl, Pratyush Mishra, Akshayaram Srinivasan, Raluca Ada Popa. *USENIX Security*, 2021. 

- Systematic Evaluation of Privacy Risks of Machine Learning Models. **[Topic: IA]**
  [[pdf]](https://www.usenix.org/system/files/sec21-song.pdf)
  - Liwei Song, Prateek Mittal. *USENIX Security*, 2021. 

- Explanation-Guided Backdoor Poisoning Attacks Against Malware Classifiers. **[Topic: Backdoor]**
  [[pdf]](https://www.usenix.org/system/files/sec21-severi.pdf)
  - Giorgio Severi, Jim Meyer, Scott Coull, Alina Oprea. *USENIX Security*, 2021. 

- Cerebro: A Platform for Multi-Party Cryptographic Collaborative Learning. **[Topic: MPC]**
  [[pdf]](https://www.usenix.org/system/files/sec21-zheng.pdf)
  - Wenting Zheng, Ryan Deng, Weikeng Chen, Raluca Ada Popa, Aurojit Panda, Ion Stoica. *USENIX Security*, 2021. 

- T-Miner: A Generative Approach to Defend Against Trojan Attacks on DNN-based Text Classification. **[Topic: Backdoor]**
  [[pdf]](https://www.usenix.org/system/files/sec21-azizi.pdf)
  - Ahmadreza Azizi, Ibrahim Asadullah Tahmid, Asim Waheed, Neal Mangaokar, Jiameng Pu, Mobin Javed, Chandan K. Reddy, Bimal Viswanath, Virginia Tech. *USENIX Security*, 2021. 

- Defeating DNN-Based Traffic Analysis Systems in Real-Time With Blind Adversarial Perturbations. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec21-nasr.pdf)
  - Milad Nasr, Alireza Bahramali, Amir Houmansadr. *USENIX Security*, 2021. 

- Data Poisoning Attacks to Local Differential Privacy Protocols. **[Topic: PA & DP]**
  [[pdf]](https://www.usenix.org/system/files/sec21-cao-xiaoyu.pdf)
  - Xiaoyu Cao, Jinyuan Jia, Neil Zhenqiang Gong. *USENIX Security*, 2021. 

- How to Make Private Distributed Cardinality Estimation Practical, and Get Differential Privacy for Free. **[Topic: DP]**
  [[pdf]](https://www.usenix.org/conference/usenixsecurity21/presentation/hu-changhui)
  - Changhui Hu, Jin Li, Zheli Liu, Xiaojie Guo, Yu Wei, and Xuan Guang, Grigorios Loukides, Changyu Dong. *USENIX Security*, 2021. 

- SLAP: Improving Physical Adversarial Examples with Short-Lived Adversarial Perturbations. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec21-lovisotto.pdf)
  - Giulio Lovisotto, Henry Turner, Ivo Sluganovic, Martin Strohmeier, Ivan Martinovic. *USENIX Security*, 2021. 

- WaveGuard: Understanding and Mitigating Audio Adversarial Examples. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec21-hussain.pdf)
  - Shehzeen Hussain, Paarth Neekhara, Shlomo Dubnov, Julian McAuley, Farinaz Koushanfar. *USENIX Security*, 2021. 

- Graph Backdoor. **[Topic: Backdoor]**
  [[pdf]](https://www.usenix.org/system/files/sec21-xi.pdf)
  - Zhaohan Xi, Ren Pang, Shouling Ji, Ting Wang. *USENIX Security*, 2021. 

- Entangled Watermarks as a Defense against Model Extraction. **[Topic: Watermark]**
  [[pdf]](https://www.usenix.org/system/files/sec21-jia.pdf)
  - Hengrui Jia, Christopher A. Choquette-Choo, Varun Chandrasekaran, Nicolas Papernot. *USENIX Security*, 2021. 

- Too Good to Be Safe: Tricking Lane Detection in Autonomous Driving with Crafted Perturbations. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec21-jing.pdf)
  - Pengfei Jing, Qiyi Tang, Yuefeng Du,  Lei Xue, Xiapu Luo, Ting Wang, Sen Nie, Shi Wu. *USENIX Security*, 2021. 

- Fantastic Four: Honest-Majority Four-Party Secure Computation With Malicious Security. **[Topic: MPC]**
  [[pdf]](https://www.usenix.org/system/files/sec21-dalskov.pdf)
  - Anders Dalskov, Daniel Escudero, Marcel Keller. *USENIX Security*, 2021. 

- Locally Differentially Private Analysis of Graph Statistics. **[Topic: DP]**
  [[pdf]](https://www.usenix.org/system/files/sec21-imola.pdf)
  - Jacob Imola, Takao Murakami, Kamalika Chaudhuri. *USENIX Security*, 2021. 

- Demon in the Variant: Statistical Analysis of DNNs for Robust Backdoor Contamination Detection. **[Topic: Backdoor]**
  [[pdf]](https://www.usenix.org/system/files/sec21-tang-di.pdf)
  - Di Tang, XiaoFeng Wang, Haixu Tang, Kehuan Zhang. *USENIX Security*, 2021. 

- Stealing Links from Graph Neural Networks. **[Topic: GNN]**
  [[pdf]](https://www.usenix.org/system/files/sec21-he-xinlei.pdf)
  - Xinlei He, Jinyuan Jia, Michael Backes, Neil Zhenqiang Gong, Yang Zhang. *USENIX Security*, 2021. 

- Adversarial Policy Training against Deep Reinforcement Learning. **[Topic: AEs & RL]**
  [[pdf]](https://www.usenix.org/system/files/sec21-wu-xian.pdf)
  - Xian Wu, Wenbo Guo, Hua Wei, Xinyu Xing. *USENIX Security*, 2021. 

## Papers in CCS
### ACM CCS '2023
### ACM CCS '2022
### ACM CCS '2021
- Cert-RNN: Towards Certifying the Robustness of Recurrent Neural Networks. **[Topic: AEs]**
  [[pdf]](https://nesa.zju.edu.cn/download/dty_pdf_cert_rnn.pdf)
  - Tianyu Du, Shouling Ji, Lujia Shen, Yao Zhang, Jinfeng Li, Jie Shi, Chengfang Fang, Jianwei Yin, Raheem Beyah, Ting Wang. *ACM CCS*, 2021.
- AHEAD: Adaptive Hierarchical Decomposition for Range Query under Local Differential Privacy. **[Topic: LDP]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3485668)
  - Linkang Du, Zhikun Zhang, Shaojie Bai, Changchang Liu, Shouling Ji, Peng Cheng, Jiming Chen. *ACM CCS*, 2021.
- Unleashing the Tiger: Inference Attacks on Split Learning. **[Topic: SL]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3485259)
  - Dario Pasquini, Giuseppe Ateniese, Massimo Bernaschi. *ACM CCS*, 2021.
- TableGAN-MCA: Evaluating Membership Collisions of GAN-Synthesized Tabular Data Releasing. **[Topic: GAN]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3485251)
  - Aoting Hu, Renjie Xie, Zhigang Lu, Aiqun Hu, Minhui Xue. *ACM CCS*, 2021.
- "I need a better description": An Investigation Into User Expectations For Differential Privacy. **[Topic: DP]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3485252)
  - Rachel Cummings, Gabriel Kaptchuk, Elissa M. Redmiles. *ACM CCS*, 2021.
- Locally Private Graph Neural Networks. **[Topic: GNNs]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3484565)
  - Sina Sajadmanesh, Daniel Gatica-Perez. *ACM CCS*, 2021.
- A One-Pass Distributed and Private Sketch for Kernel Sums with Applications to Machine Learning at Scale. **[Topic: DP]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3485255)
  - Benjamin Coleman, Anshumali Shrivastava. *ACM CCS*, 2021.

# AI-Security-Resources

This Github repository summarizes a list of research papers on **AI security** from the BIG-4 academic conferences, namely 
IEEE Symposium on Security and Privacy (**S&P**), Network and Distributed System Security Symposium (**NDSS**), **USENIX Security** Symposium, and ACM Conference on Computer and Communications Security (**CCS**). 

*This repository is supported by the Trustworthy Artificial Intelligence ([T-AI](http://trustai.cse.hust.edu.cn)) Lab at  Huazhong University of Science and Technology (HUST).*

We will try our best to continuously maintain this Github Repository in a weekly manner.

## News
* 2025/4/23: Zongren Ma added S&P 2023&2024, CCS 2024 papers
* 2025/4/22: Pinzheng Wu added NDSS 2023&2024&2025, USENIX Security 2023&2024 papers.
* 2023/8/6:  Junyu Shi added CCS papers.
* 2023/7/25: Hangtao Zhang added NDSS & USENIX Security papers.
* 2023/7/24: Ziqi Zhou added S&P papers.
* 2023/7/23: We create the AI-Security-Resources repository.


## Table of Contents

- [Papers in S&P](#papers-in-sp)
  - [S&P'2024](#papers-in-sp24)
  - [S&P'2023](#papers-in-sp23)
  - [S&P'2022](#papers-in-sp22)
  - [S&P'2021](#papers-in-sp21)
- [Papers in NDSS](#papers-in-ndss)
  - [NDSS'2025](#NDSS'2025)
  - [NDSS'2024](#NDSS'2024)
  - [NDSS'2023](#NDSS'2023)
  - [NDSS'2022](#NDSS'2022)
  - [NDSS'2021](#NDSS'2021)
- [Papers in USENIX Security](#papers-in-usenix-security)
  - [USENIX Security'2024](#USENIX-Security'2024)
  - [USENIX Security'2023](#USENIX-Security'2023)
  - [USENIX Security'2022](#USENIX-Security'2022)
  - [USENIX Security'2021](#USENIX-Security'2021)
- [Papers in CCS](#papers-in-ccs)
  - [CCS'2024](#CCS'2024)
  - [CCS'2023](#CCS'2023)
  - [CCS'2022](#CCS'2022)
  - [CCS'2021](#CCS'2021)


## Papers in S&P

### S&P'2024

- Securely Fine-tuning Pre-trained Encoders Against Adversarial Examples. **[Topic: AEs]**
  [[pdf]](https://arxiv.org/abs/2403.10801)
  - Ziqi Zhou, Minghui Li, Wei Liu, Shengshan Hu, Yechao Zhang, Wei Wan, Lulu Xue, Leo Yu Zhang, Dezhong Yao, Hai Jin. *IEEE Symposium on Security and Privacy*, 2024.

- Why Does Little Robustness Help? A Further Step Towards Understanding Adversarial Transferability. **[Topic: AEs]**
  [[Code]](https://github.com/CGCL-codes/TransferAttackSurrogates)[[pdf]](https://arxiv.org/pdf/2307.07873.pdf)
  - Yechao Zhang, Shengshan Hu, Leo Yu Zhang, Junyu Shi, Xiaogeng Liu, Minghui Li, Wei Wan, Hai Jin. *IEEE Symposium on Security and Privacy*, 2024.

- LABRADOR: Response Guided Directed Fuzzing for Black-box IoT Devices. **[Topic: AEs]**
  [[pdf]](https://ieeexplore.ieee.org/document/10646723)
  - Hangtian Liu; Shuitao Gan; Chao Zhang; Zicong Gao; Hongqi Zhang; Xiangzhi Wang. *IEEE Symposium on Security and Privacy*, 2024.

- SneakyPrompt: Jailbreaking Text-to-image Generative Models. **[Topic: AEs]**
  [[Code]](https://github.com/Yuchen413/text2image_safety)[[pdf]](https://arxiv.org/abs/2305.12082)
  - Yuchen Yang, Bo Hui, Haolin Yuan, Neil Gong, Yinzhi Cao. *IEEE Symposium on Security and Privacy*, 2024.

- SmartInv: Multimodal Learning for Smart Contract Invariant Inference.**[Topic: AEs]**
  [[Code]](https://github.com/columbia/SmartInv)[[pdf]](https://ieeexplore.ieee.org/document/10646885)
  - Sally Junsong Wang; Kexin Pei; Junfeng Yang. *IEEE Symposium on Security and Privacy*, 2024.

- AVA: Inconspicuous Attribute Variation-based Adversarial Attack bypassing DeepFake Detection.**[Topic: AEs]**
 [[pdf]](https://arxiv.org/abs/2312.08675)
  - Xiangtao Meng, Li Wang, Shanqing Guo, Lei Ju, Qingchuan Zhao. *IEEE Symposium on Security and Privacy*, 2024.

- Robust Backdoor Detection for Deep Learning via Topological Evolution Dynamics.**[Topic: Backdoor]**
 [[pdf]](https://arxiv.org/abs/2312.02673)
  - Xiaoxing Mo, Yechao Zhang, Leo Yu Zhang, Wei Luo, Nan Sun, Shengshan Hu, Shang Gao, Yang Xiang. *IEEE Symposium on Security and Privacy*, 2024.

- MEA-Defender: A Robust Watermark against Model Extraction Attack.**[Topic: AEs]**
 [[pdf]](https://arxiv.org/abs/2401.15239)
  - Peizhuo Lv, Hualong Ma, Kai Chen, Jiachen Zhou, Shengzhi Zhang, Ruigang Liang, Shenchen Zhu, Pan Li, Yingjun Zhang. *IEEE Symposium on Security and Privacy*, 2024.

- BounceAttack: A Query-Efficient Decision-based Adversarial Attack by Bouncing into the Wild.**[Topic: AEs]**
 [[pdf]](https://ieeexplore.ieee.org/document/10646713)
  - Jie Wan; Jianhao Fu; Lijin Wang; Ziqi Yang. *IEEE Symposium on Security and Privacy*, 2024.

- SoK: Explainable Machine Learning in Adversarial Environments.**[Topic: AEs]**
 [[pdf]](https://ieeexplore.ieee.org/document/10646794)
  - Maximilian Noppel; Christian Wressnegger. *IEEE Symposium on Security and Privacy*, 2024.

- Poisoned ChatGPT Finds Work for Idle Hands: Exploring Developers' Coding Practices with Insecure Suggestions from Poisoned AI Models.**[Topic: AEs]**
 [[pdf]](https://arxiv.org/abs/2312.06227)
  - Sanghak Oh, Kiho Lee, Seonhye Park, Doowon Kim, Hyoungshick Kim. *IEEE Symposium on Security and Privacy*, 2024.

- Transferable Multimodal Attack on Vision-Language Pre-training Models.**[Topic: AEs]**
 [[pdf]](https://ieeexplore.ieee.org/document/10646738)
  - Haodi Wang; Kai Dong; Zhilei Zhu; Haotong Qin; Aishan Liu; Xiaolin Fang. *IEEE Symposium on Security and Privacy*, 2024.

- Exploring the Orthogonality and Linearity of Backdoor Attacks.**[Topic: Backdoor]**
 [[pdf]](https://ieeexplore.ieee.org/abstract/document/10646641)
  - Siyuan Cheng; Guangyu Shen; Guanhong Tao; Kaiyuan Zhang; Zhuo Zhang; Shengwei An. *IEEE Symposium on Security and Privacy*, 2024.

- OdScan: Backdoor Scanning for Object Detection Models.**[Topic: Backdoor]**
 [[pdf]](https://ieeexplore.ieee.org/document/10646667)
  - Kaiyuan Zhang; Siyuan Cheng; Guangyu Shen; Guanhong Tao; Shengwei An; Anuran Makur. *IEEE Symposium on Security and Privacy*, 2024.

- Need for Speed: Taming Backdoor Attacks with Speed and Precision.**[Topic: Backdoor]**
 [[pdf]](https://ieeexplore.ieee.org/document/10646685)
  - Zhuo Ma; Yilong Yang; Yang Liu; Tong Yang; Xinjing Liu; Teng Li. *IEEE Symposium on Security and Privacy*, 2024.

- BAFFLE: Hiding Backdoors in Offline Reinforcement Learning Datasets.**[Topic: Backdoor]**
 [[pdf]](https://arxiv.org/abs/2210.04688)
  - Chen Gong, Zhou Yang, Yunpeng Bai, Junda He, Jieke Shi, Kecen Li, Arunesh Sinha, Bowen Xu, Xinwen Hou, David Lo, Tianhao Wang. *IEEE Symposium on Security and Privacy*, 2024.

- DeepVenom: Persistent DNN Backdoors Exploiting Transient Weight Perturbations in Memories.**[Topic: Backdoor]**
  [[Code]](https://github.com/casrl/DeepVenom)[[pdf]](https://ieeexplore.ieee.org/document/10646710)
  - Kunbei Cai; Md Hafizul Islam Chowdhuryy; Zhenkai Zhang; Fan Yao. *IEEE Symposium on Security and Privacy*, 2024.

- LLMs Cannot Reliably Identify and Reason About Security Vulnerabilities (Yet?): A Comprehensive Evaluation, Framework, and Benchmarks.**[Topic: AEs]**
 [[pdf]](https://arxiv.org/abs/2312.12575)
  - Saad Ullah, Mingji Han, Saurabh Pujar, Hammond Pearce, Ayse Coskun, Gianluca Stringhini. *IEEE Symposium on Security and Privacy*, 2024.

- BELT: Old-School Backdoor Attacks can Evade the State-of-the-Art Defense with Backdoor Exclusivity Lifting.**[Topic: Backdoor]**
 [[pdf]](https://arxiv.org/abs/2312.04902)
  - Huming Qiu, Junjie Sun, Mi Zhang, Xudong Pan, Min Yang. *IEEE Symposium on Security and Privacy*, 2024.

- You Only Prompt Once: On the Capabilities of Prompt Learning on Large Language Models to Tackle Toxic Content.**[Topic: AEs]**
 [[pdf]](https://arxiv.org/abs/2308.05596)
  - Xinlei He, Savvas Zannettou, Yun Shen, Yang Zhang. *IEEE Symposium on Security and Privacy*, 2024.

- LOKI: Large-scale Data Reconstruction Attack against Federated Learning through Model Manipulation.**[Topic: AEs]**
 [[pdf]](https://arxiv.org/abs/2303.12233)
  - Joshua C. Zhao, Atul Sharma, Ahmed Roushdy Elkordy, Yahya H. Ezzeldin, Salman Avestimehr, Saurabh Bagchi. *IEEE Symposium on Security and Privacy*, 2024.

- Text-CRS: A Generalized Certified Robustness Framework against Textual Adversarial Attacks.**[Topic: AEs]**
 [[pdf]](https://ieeexplore.ieee.org/document/10646716)
  - Xinyu Zhang; Hanbin Hong; Yuan Hong; Peng Huang; Binghui Wang; Zhongjie Ba. *IEEE Symposium on Security and Privacy*, 2024.

- MM-BD: Post-Training Detection of Backdoor Attacks with Arbitrary Backdoor Pattern Types Using a Maximum Margin Statistic.**[Topic: Backdoor]**
 [[pdf]](https://arxiv.org/abs/2205.06900)
  - Hang Wang, Zhen Xiang, David J. Miller, George Kesidis. *IEEE Symposium on Security and Privacy*, 2024.

-BadVFL: Backdoor Attacks in Vertical Federated Learning.**[Topic: Backdoor]**
 [[pdf]](https://arxiv.org/abs/2304.08847)
  - Mohammad Naseri, Yufei Han, Emiliano De Cristofaro. *IEEE Symposium on Security and Privacy*, 2024.

-Multi-Instance Adversarial Attack on GNN-Based Malicious Domain Detection.**[Topic: GNN]**
 [[pdf]](https://arxiv.org/pdf/2308.11754)
  - Mahmoud Nazzal, Issa Khalil, Abdallah Khreishah, NhatHai Phan, and Yao Ma. *IEEE Symposium on Security and Privacy*, 2024.

-Distribution Preserving Backdoor Attack in Self-supervised Learning.**[Topic: Backdoor]**
 [[pdf]](https://ieeexplore.ieee.org/abstract/document/10646825)
  - Guanhong Tao; Zhenting Wang; Shiwei Feng; Guangyu Shen; Shiqing Ma; Xiangyu Zhang. *IEEE Symposium on Security and Privacy*, 2024.
### S&P'2023

- SoK: Let the Privacy Games Begin! A Unified Treatment of Data Inference Privacy in Machine Learning.**[Topic: ML]**
 [[pdf]](https://arxiv.org/abs/2212.10986)
  - Ahmed Salem, Giovanni Cherubin, David Evans, Boris Köpf, Andrew Paverd, Anshuman Suri, Shruti Tople, Santiago Zanella-Béguelin. *IEEE Symposium on Security and Privacy*, 2023.

- Analyzing Leakage of Personally Identifiable Information in Language Models.**[Topic: LM]**
 [[pdf]](https://arxiv.org/abs/2302.00539)
  - Nils Lukas, Ahmed Salem, Robert Sim, Shruti Tople, Lukas Wutschitz, Santiago Zanella-Béguelin. *IEEE Symposium on Security and Privacy*, 2023.

- D-DAE: Defense-Penetrating Model Extraction Attacks.**[Topic: AEs]**
  [[Code]](https://github.com/grWHU/D-DAE)[[pdf]](https://ieeexplore.ieee.org/document/10179406)
  - Kunbei Cai; Md Hafizul Islam Chowdhuryy; Zhenkai Zhang; Fan Yao. *IEEE Symposium on Security and Privacy*, 2023.

- Disguising Attacks with Explanation-Aware Backdoors.**[Topic: Backdoor]**
 [[pdf]](https://ieeexplore.ieee.org/document/10179308)
  - Maximilian Noppel; Lukas Peter; Christian Wressnegger. *IEEE Symposium on Security and Privacy*, 2023.

- AI-Guardian: Defeating Adversarial Attacks using Backdoors.**[Topic: Backdoor]**
 [[pdf]](https://ieeexplore.ieee.org/document/10179473)
  - Hong Zhu; Shengzhi Zhang; Kai Chen. *IEEE Symposium on Security and Privacy*, 2023.

- BayBFed: Bayesian Backdoor Defense for Federated Learning.**[Topic: Backdoor]**
 [[pdf]](https://ieeexplore.ieee.org/document/10179362)
  - Kavita Kumari; Phillip Rieger; Hossein Fereidooni; Murtuza Jadliwala; Ahmad-Reza Sadeghi. *IEEE Symposium on Security and Privacy*, 2023.

- edeem Myself: Purifying Backdoors in Deep Learning Models using Self Attention Distillation.**[Topic: Backdoor]**
 [[pdf]](https://ieeexplore.ieee.org/document/10179375)
  - Xueluan Gong; Yanjiao Chen; Wang Yang; Qian Wang; Yuzhe Gu; Huayang Huang. *IEEE Symposium on Security and Privacy*, 2023.

- ImU: Physical Impersonating Attack for Face Recognition System with Natural Style Changes.**[Topic: AEs]**
 [[pdf]](https://ieeexplore.ieee.org/document/10179360)
  - Shengwei An; Yuan Yao; Qiuling Xu; Shiqing Ma; Guanhong Tao; Siyuan Cheng. *IEEE Symposium on Security and Privacy*, 2023.

- FedRecover: Recovering from Poisoning Attacks in Federated Learning using Historical Information.**[Topic: AEs]**
 [[pdf]](https://arxiv.org/abs/2210.10936)
  - Xiaoyu Cao, Jinyuan Jia, Zaixi Zhang, Neil Zhenqiang Gong. *IEEE Symposium on Security and Privacy*, 2023.

- On The Empirical Effectiveness of Unrealistic Adversarial Hardening Against Realistic Adversarial Attacks.**[Topic: AEs]**
 [[pdf]](https://arxiv.org/abs/2202.03277)
  - Salijona Dyrmishi, Salah Ghamizi, Thibault Simonetto, Yves Le Traon, Maxime Cordy. *IEEE Symposium on Security and Privacy*, 2023.
### S&P'2022

- “Adversarial Examples” for Proof-of-Learning. **[Topic: AEs]**
  [[pdf]](https://arxiv.org/pdf/2108.09454.pdf)
  - Rui Zhang, Jian Liu, Yuan Ding, Zhibo Wang, Qingbiao Wu, and Kui Ren. *IEEE Symposium on Security and Privacy*, 2022.

- Transfer Attacks Revisited: A Large-Scale Empirical Study in Real Computer Vision Settings. **[Topic:AEs]**
  [[pdf]](https://arxiv.org/pdf/2204.04063.pdf)
  - Yuhao Mao, Chong Fu, Saizhuo Wang, Shouling Ji, Xuhong Zhang, Zhenguang Liu, Jun Zhou, Alex X.Liu, Raheem Beyah, Ting Wang. *IEEE Symposium on Security and Privacy*, 2022.

- Bad Characters: Imperceptible NLP Attacks. **[Topic: AEs]**
  [[Code]](https://github.com/nickboucher/imperceptible)[[pdf]](https://arxiv.org/pdf/2106.09898.pdf)
  - Nicholas Boucher, Ilia Shumailov, Ross Anderson, Nicolas Papernot. *IEEE Symposium on Security and Privacy*, 2022.

- Universal 3-Dimensional Perturbations for Black-Box Attacks on Video Recognition Systems. **[Topic: AEs]**
  [[pdf]](https://arxiv.org/pdf/2107.04284.pdf)
  - Shangyu Xie, Han Wang, Yu Kong, Yuan Hong. *IEEE Symposium on Security and Privacy*, 2022.

- BadEncoder: Backdoor Attacks to Pre-trained Encoders in Self-Supervised Learning. **[Topic: Backdoor]**
  [[Code]](https://github.com/jinyuan-jia/BadEncoder)[[pdf]](https://arxiv.org/pdf/2108.00352.pdf)
  - Jinyuan Jia, Yupei Liu, Neil Zhenqiang Gong. *IEEE Symposium on Security and Privacy*, 2022.

- PICCOLO: Exposing Complex Backdoors in NLP Transformer Models. **[Topic: Backdoor]**
  [[pdf]](https://par.nsf.gov/servlets/purl/10335908)
  - Yingqi Liu, Guangyu Shen, Guanhong Tao, Shengwei An, Shiqing Ma, Xiangyu Zhang. *IEEE Symposium on Security and Privacy*, 2022.

- Membership Inference Attacks From First Principles. **[Topic: MIA]**
  [[pdf]](https://arxiv.org/pdf/2112.03570.pdf)
  - Nicholas Carlini, Steve Chien, Milad Nasr, Shuang Song, Andreas Terzis, Florian Tramer. *IEEE Symposium on Security and Privacy*, 2022.

- Back to the Drawing Board: A Critical Evaluation of Poisoning Attacks on Production Federated Learning. **[Topic: PA & FL]**
  [[pdf]](https://arxiv.org/pdf/2108.10241.pdf)
  - Virat Shejwalkar, Amir Houmansadr, Peter Kairouz, Daniel Ramage. *IEEE Symposium on Security and Privacy*, 2022.

- Model Stealing Attacks Against Inductive Graph Neural Networks. **[Topic: MSA & GNN]**
  [[pdf]](https://arxiv.org/pdf/2112.08331.pdf)
  - Yun Shen, Xinlei He, Yufei Han, Yang Zhang. *IEEE Symposium on Security and Privacy*, 2022.
 
- SoK: How Robust is Image Classification Deep Neural Network Watermarking? **[Topic: Watermark]**
  [[pdf]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9833693)
  - Nils Lukas, Edward Jiang, Xinda Li, Florian Kerschbaum. *IEEE Symposium on Security and Privacy*, 2022.


### S&P'2021

- Hear "No Evil", See "Kenansville": Efficient and Transferable Black-Box Attacks on Speech Recognition and Voice Identification Systems. **[Topic: AEs]**
  [[pdf]](https://arxiv.org/pdf/1910.05262.pdf)
  - Hadi Abdullah, Muhammad Sajidur Rahman, Washington Garcia, Logan Blue, Kevin Warren, Anurag Swarnim Yadav, Tom Shrimpton, Patrick Traynor. *IEEE Symposium on Security and Privacy*, 2021.

- SoK: The Faults in our ASRs: An Overview of Attacks against Automatic Speech Recognition and Speaker Identification Systems. **[Topic: AEs]**
[  [pdf]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9519395)
  - Hadi Abdullah, Kevin Warren, Vincent Bindschaedler, Nicolas Papernot, Patrick Traynor. *IEEE Symposium on Security and Privacy*, 2021.

- Invisible for both Camera and LiDAR: Security of Multi-Sensor Fusion based Perception in Autonomous Driving Under Physical-World Attacks. **[Topic: AEs]**
  [[pdf]](https://arxiv.org/pdf/2106.09249.pdf)
  - Yulong Cao, Ningfei Wang, Chaowei Xiao, Dawei Yang, Jin Fang, Ruigang Yang, Qi Alfred Chen, Mingyan Liu, Bo Li. *IEEE Symposium on Security and Privacy*, 2021.

- Who is Real Bob? Adversarial Attacks on Speaker Recognition Systems. **[Topic: AEs]**
  [[pdf]](https://arxiv.org/pdf/1911.01840.pdf)
  - Guangke Chen, Sen Chen, Lingling Fan, Xiaoning Du, Zhe Zhao, Fu Song, Yang Liu. *IEEE Symposium on Security and Privacy*, 2021.

- Adversarial Watermarking Transformer: Towards Tracing Text Provenance with Data Hiding. **[Topic: Watermark]**
  [[pdf]](https://arxiv.org/pdf/2009.03015.pdf)
  - Sahar Abdelnabi, Mario Fritz. *IEEE Symposium on Security and Privacy*, 2021.


## Papers in NDSS 

### NDSS'2025

- A Method to Facilitate Membership Inference Attacks in Deep Learning Models.**[Topic: ML]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-41-paper.pdf)
  - Zitao Chen, Karthik Pattabiraman. *Network and Distributed System Security*, 2025.

- Black-box Membership Inference Attacks against Fine-tuned Diffusion Models.**[Topic:Diffusion Model]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-324-paper.pdf)
  - Yan Pang, Tianhao Wang. *Network and Distributed System Security*, 2025.

- BumbleBee: Secure Two-party Inference Framework for Large Transformers.**[Topic: Transformer]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-57-paper.pdf)
  - Wen-jie Lu, Zhicong Huang, Zhen Gu, Jingyu Li, Jian Liu, Cheng Hong, Kui Ren, Tao Wei, Wenguang Chen. *Network and Distributed System Security*, 2025.

- CENSOR: Defense Against Gradient Inversion via Orthogonal Subspace Bayesian Sampling.**[Topic: FL]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-915-paper.pdf)
  - Kaiyuan Zhang, Siyuan Cheng, Guangyu Shen, Bruno Ribeiro, Shengwei An, Pin-Yu Chen, Xiangyu Zhang, Ninghui Li. *Network and Distributed System Security*, 2025.

- CLIBE: Detecting Dynamic Backdoors in Transformer-based NLP Models.**[Topic: Backdoor]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-478-paper.pdf)
  - Rui Zeng, Xi Chen, Yuwen Pu, Xuhong Zhang, Tianyu Du, Shouling Ji. *Network and Distributed System Security*, 2025.

- Compiled Models, Built-In Exploits: Uncovering Pervasive Bit-Flip Attack Surfaces in DNN Executables.**[Topic: DNN]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-419-paper.pdf)
  - Yanzuo Chen, Zhibo Liu, Yuanyuan Yuan, Sihang Hu, Tianxiang Li, Shuai Wang. *Network and Distributed System Security*, 2025.

- Difference: Fencing Membership Privacy With Diffusion Models.**[Topic:Diffusion Model]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-s298-paper.pdf)
  - Yuefeng Peng, Ali Naseh, Amir Houmansadr. *Network and Distributed System Security*, 2025.

- Explanation as a Watermark: Towards Harmless and Multi-bit Model Ownership Verification via Watermarking Feature Attribution.**[Topic:Backdoor]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-338-paper.pdf)
  - Shuo Shao, Yiming Li, Hongwei Yao, Yiling He, Zhan Qin, Kui Ren. *Network and Distributed System Security*, 2025.

- Generating API Parameter Security Rules with LLM for API Misuse Detection.**[Topic:LLM]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-465-paper.pdf)
  - Jinghua Liu, Yi Yang, Kai Chen, Miaoqian Lin. *Network and Distributed System Security*, 2025.

- Magmaw: Modality-Agnostic Adversarial Attacks on Machine Learning-Based Wireless Communication Systems.**[Topic:ML]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-s336-paper.pdf)
  - Jung-Woo Chang, Ke Sun, Nasimeh Heydaribeni, Seira Hidano, Xinyu Zhang, Farinaz Koushanfar. *Network and Distributed System Security*, 2025.

- Passive Inference Attacks on Split Learning via Adversarial Regularization.**[Topic:SL]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-30-paper.pdf)
  - Xiaochen Zhu, Xinjian Luo, Yuncheng Wu, Yangfan Jiang, Xiaokui Xiao, Beng Chin Ooi. *Network and Distributed System Security*, 2025.

- Reinforcement Unlearning.**[Topic:Machine unlearning]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-80-paper.pdf)
  - Dayong Ye, Tianqing Zhu, Congcong Zhu, Derui Wang, Kun Gao, Zewei Shi, Sheng Shen, Wanlei Zhou, Minhui Xue. *Network and Distributed System Security*, 2025.

- The Midas Touch: Triggering the Capability of LLMs for RM-API Misuse Detection.**[Topic:LLM]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-816-paper.pdf)
  - Yi Yang, Jinghua Liu, Kai Chen, Miaoqian Lin. *Network and Distributed System Security*, 2025.

- The Philosopher's Stone: Trojaning Plugins of Large Language Models.**[Topic:LLM]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-s164-paper.pdf)
  - Tian Dong, Minhui Xue, Guoxing Chen, Rayne Holland, Yan Meng, Shaofeng Li, Zhen Liu, Haojin Zhu. *Network and Distributed System Security*, 2025.

- TrajDeleter: Enabling Trajectory Forgetting in Offline Reinforcement Learning Agents.**[Topic:RL]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-126-paper.pdf)
  - Chen Gong, Kecen Li, Jin Yao, Tianhao Wang. *Network and Distributed System Security*, 2025.

- Understanding Data Importance in Machine Learning Attacks: Does Valuable Data Pose Greater Harm?**[Topic:ML]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-331-paper.pdf)
  - Rui Wen, Michael Backes, Yang Zhang. *Network and Distributed System Security*, 2025.

- A New PPML Paradigm for Quantized Models.**[Topic:PPML]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-2872-paper.pdf)
  - Tianpei Lu, Bingsheng Zhang, Xiaoyuan Zhang, Kui Ren. *Network and Distributed System Security*, 2025.

- ASGARD: Protecting On-Device Deep Neural Networks with Virtualization-Based Trusted Execution Environments.**[Topic:DNN]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-449-paper.pdf)
  - Myungsuk Moon, Minhee Kim, Joonkyo Jung, Dokyung Song. *Network and Distributed System Security*, 2025.

- BARBIE: Robust Backdoor Detection Based on Latent Separability.**[Topic:Backdoor]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-179-paper.pdf)
  - Hanlei Zhang, Yijie Bai, Yanjiao Chen, Zhongming Ma, Wenyuan Xu. *Network and Distributed System Security*, 2025.

- Beyond Classification: Inferring Function Names in Stripped Binaries via Domain Adapted LLMs.**[Topic:LLM]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-797-paper.pdf)
  - Linxi Jiang, Xin Jin, Zhiqiang Lin. *Network and Distributed System Security*, 2025.

- BitShield: Defending Against Bit-Flip Attacks on DNN Executables.**[Topic:DNN]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-1463-paper.pdf)
  - Yanzuo Chen, Yuanyuan Yuan, Zhibo Liu, Sihang Hu, Tianxiang Li, Shuai Wang. *Network and Distributed System Security*, 2025.

- Defending Against Membership Inference Attacks on Iteratively Pruned Deep Neural Networks.**[Topic:MIA]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-90-paper.pdf)
  - Jing Shang, Jian Wang, Kailun Wang, Jiqiang Liu, Nan Jiang, Md. Armanuzzaman, Ziming Zhao. *Network and Distributed System Security*, 2025.

- DLBox: New Model Training Framework for Protecting Training Data.**[Topic:model training framework]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-3001-paper.pdf)
  - Jaewon Hur, Juheon Yi, Cheolwoo Myung, Sangyun Kim, Youngki Lee, Byoungyoung Lee. *Network and Distributed System Security*, 2025.

- Do We Really Need to Design New Byzantine-robust Aggregation Rules?**[Topic:FL]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-1796-paper.pdf)
  - Minghong Fang, Seyedsina Nabavirazavi, Zhuqing Liu, Wei Sun, Sundaraja Sitharama Iyengar, Haibo Yang. *Network and Distributed System Security*, 2025.

- DShield: Defending against Backdoor Attacks on Graph Neural Networks via Discrepancy Learning.**[Topic:Backdoor]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-798-paper.pdf)
  - Hao Yu, Chuan Ma, Xinhang Wan, Jun Wang, Tao Xiang, Meng Shen, Xinwang Liu. *Network and Distributed System Security*, 2025.

- From Large to Mammoth: A Comparative Evaluation of Large Language Models in Vulnerability Detection.**[Topic:LLM]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-1491-paper.pdf)
  - Jie Lin, David Mohaisen. *Network and Distributed System Security*, 2025.

- I Know What You Asked: Prompt Leakage via KV-Cache Sharing in Multi-Tenant LLM Serving.**[Topic:LLM]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-1772-paper.pdf)
  - Guanlong Wu, Zheng Zhang, Yao Zhang, Weili Wang, Jianyu Niu, Ye Wu, Yinqian Zhang. *Network and Distributed System Security*, 2025.

- I know what you MEME! Understanding and Detecting Harmful Memes with Multimodal Large Language Models.**[Topic:MLLM]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-415-paper.pdf)
  - Yong Zhuang, Keyan Guo, Juan Wang, Yiheng Jing, Xiaoyang Xu, Wenzhe Yi, Mengda Yang, Bo Zhao, Hongxin Hu. *Network and Distributed System Security*, 2025.

- IsolateGPT: An Execution Isolation Architecture for LLM-Based Agentic Systems.**[Topic:LLM]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-1131-paper.pdf)
  - Yuhao Wu, Franziska Roesner, Tadayoshi Kohno, Ning Zhang, Umar Iqbal. *Network and Distributed System Security*, 2025.

- L-HAWK: A Controllable Physical Adversarial Patch Against a Long-Distance Target.**[Topic:physical adversarial patch attacks]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-26-paper.pdf)
  - Taifeng Liu, Yang Liu, Zhuo Ma, Tong Yang, Xinjing Liu, Teng Li, Jianfeng Ma. *Network and Distributed System Security*, 2025.

- LADDER: Multi-Objective Backdoor Attack via Evolutionary Algorithm.**[Topic:Backdoor]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-1061-paper.pdf)
  - Dazhuang Liu, Yanqi Qiao, Rui Wang, Kaitai Liang, Georgios Smaragdakis. *Network and Distributed System Security*, 2025.

- LLMPirate: LLMs for Black-box Hardware IP Piracy.**[Topic:LLM]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-2059-paper.pdf)
  - Vasudev Gohil, Matthew DeLorenzo, Veera Vishwa Achuta Sai Venkat Nallam, Joey See, Jeyavijayan Rajendran. *Network and Distributed System Security*, 2025.

- PBP: Post-training Backdoor Purification for Malware Classifiers.**[Topic:Backdoor]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-603-paper.pdf)
  - Dung Thuy Nguyen, Ngoc N. Tran, Taylor T. Johnson, Kevin Leach. *Network and Distributed System Security*, 2025.

- Privacy-Preserving Data Deduplication for Enhancing Federated Learning of Language Models.**[Topic:FL]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-641-paper.pdf)
  - Aydin Abadi, Vishnu Asutosh Dasu, Sumanta Sarkar. *Network and Distributed System Security*, 2025.

- Probe-Me-Not: Protecting Pre-trained Encoders from Malicious Probing.**[Topic:transfer learning]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-928-paper.pdf)
  - Ruyi Ding, Tong Zhou, Lili Su, Aidong Adam Ding, Xiaolin Xu, Yunsi Fei. *Network and Distributed System Security*, 2025.

- PropertyGPT: LLM-driven Formal Verification of Smart Contracts through Retrieval-Augmented Property Generation.**[Topic:LLM]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-1357-paper.pdf)
  - Ye Liu, Yue Xue, Daoyuan Wu, Yuqiang Sun, Yi Li, Miaolei Shi, Yang Liu. *Network and Distributed System Security*, 2025.

- RAIFLE: Reconstruction Attacks on Interaction-based Federated Learning with Adversarial Data Manipulation.**[Topic:FL]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-363-paper.pdf)
  - Dzung Pham, Shreyas Kulkarni, Amir Houmansadr. *Network and Distributed System Security*, 2025.

- SafeSplit: A Novel Defense Against Client-Side Backdoor Attacks in Split Learning.**[Topic:Backdoor]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-1698-paper.pdf)
  - Phillip Rieger, Alessandro Pegoraro, Kavita Kumari, Tigist Abera, Jonathan Knauer, Ahmad-Reza Sadeghi. *Network and Distributed System Security*, 2025.

- Safety Misalignment Against Large Language Models.**[Topic:LLM]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-1089-paper.pdf)
  - Yichen Gong, Delong Ran, Xinlei He, Tianshuo Cong, Anyu Wang, Xiaoyun Wang. *Network and Distributed System Security*, 2025.

- Scale-MIA: A Scalable Model Inversion Attack against Secure Federated Learning via Latent Space Reconstruction.**[Topic:MIA&FL]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-644-paper.pdf)
  - Shanghao Shi, Ning Wang, Yang Xiao, Chaoyu Zhang, Yi Shi, Y. Thomas Hou, Wenjing Lou. *Network and Distributed System Security*, 2025.

- SHAFT: Secure, Handy, Accurate and Fast Transformer Inference.**[Topic:transformer-based machine learning]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-2287-paper.pdf)
  - Andes Y. L. Kei, Sherman S. M. Chow. *Network and Distributed System Security*, 2025.

- Try to Poison My Deep Learning Data? Nowhere to Hide Your Trajectory Spectrum!**[Topic:DaaS]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-1589-paper.pdf)
  - Yansong Gao, Huaibing Peng, Hua Ma, Zhi Zhang, Shuo Wang, Rayne Holland, Anmin Fu, Minhui Xue, Derek Abbott. *Network and Distributed System Security*, 2025.

- URVFL: Undetectable Data Reconstruction Attack on Vertical Federated Learning.**[Topic:VFL]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-46-paper.pdf)
  - Duanyi Yao, Songze Li, Xueluan Gong, Sizai Hou, Gaoning Pan. *Network and Distributed System Security*, 2025.

- VoiceRadar: Voice Deepfake Detection using Micro-Frequency and Compositional Analysis.**[Topic:ML]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2025-3389-paper.pdf)
  - Kavita Kumari, Maryam Abbasihafshejani, Alessandro Pegoraro, Phillip Rieger, Kamyar Arshi, Murtuza Jadliwala, Ahmad-Reza Sadeghi. *Network and Distributed System Security*, 2025.

### NDSS'2024

- Attributions for ML-based ICS Anomaly Detection: From Theory to Practice.**[Topic:ML]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-216-paper.pdf)
  - Clement Fung, Eric Zeng, Lujo Bauer. *Network and Distributed System Security*, 2024.

- Compensating Removed Frequency Components: Thwarting Voice Spectrum Reduction Attacks.**[Topic:ASR]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-150-paper.pdf)
  - Shu Wang, Kun Sun, Qi Li. *Network and Distributed System Security*, 2024.

- Crafter: Facial Feature Crafting against Inversion-based Identity Theft on Deep Models.**[Topic:防御攻击]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-326-paper.pdf)
  - Shiming Wang, Zhe Ji, Liyao Xiang, Hao Zhang, Xinbing Wang, Chenghu Zhou, Bo Li. *Network and Distributed System Security*, 2024.

- CrowdGuard: Federated Backdoor Detection in Federated Learning.**[Topic:Backdoor]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-233-paper.pdf)
  - Phillip Rieger, Torsten Krauß, Markus Miettinen, Alexandra Dmitrienko, Ahmad-Reza Sadeghi. *Network and Distributed System Security*, 2024.

- Enhance Stealthiness and Transferability of Adversarial Attacks with Class Activation Mapping Ensemble Attack.**[Topic:对抗攻击]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-164-paper.pdf)
  - Hui Xia, Rui Zhang, Zi Kang, Shuliang Jiang, Shuo Xu. *Network and Distributed System Security*, 2024.

- GNNIC: Finding Long-Lost Sibling Functions with Abstract Similarity.**[Topic:GNN]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-492-paper.pdf)
  - Qiushi Wu, Zhongshu Gu, Hani Jamjoom, Kangjie Lu. *Network and Distributed System Security*, 2024.

- LiDAR Spoofing Meets the New-Gen: Capability Improvements, Broken Assumptions, and New Attack Strategies.**[Topic:欺骗攻击]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-350-paper.pdf)
  - Takami Sato, Yuki Hayakawa, Ryo Suzuki, Yohsuke Shiiki, Kentaro Yoshioka, Qi Alfred Chen. *Network and Distributed System Security*, 2024.

- LMSanitator: Defending Prompt-Tuning Against Task-Agnostic Backdoors.**[Topic:Backdoor]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-238-paper.pdf)
  - Chengkun Wei, Wenlong Meng, Zhikun Zhang, Min Chen, Minghu Zhao, Wenjing Fang, Lei Wang, Zihui Zhang, Wenzhi Chen. *Network and Distributed System Security*, 2024.

- Low-Quality Training Data Only? A Robust Framework for Detecting Encrypted Malicious Network Traffic.**[Topic:数据集]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-81-paper.pdf)
  - Yuqi Qing, Qilei Yin, Xinhao Deng, Yihao Chen, Zhuotao Liu, Kun Sun, Ke Xu, Jia Zhang, Qi Li. *Network and Distributed System Security*, 2024.

- MPCDiff: Testing and Repairing MPC-Hardened Deep Learning Models.**[Topic:MPC-Hardened]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-380-paper.pdf)
  - Qi Pang, Yuanyuan Yuan, Shuai Wang. *Network and Distributed System Security*, 2024.

- On Precisely Detecting Censorship Circumvention in Real-World Networks.**[Topic:Censorship Circumvention]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-394-paper.pdf)
  - Ryan Wails, George Arnold Sullivan, Micah Sherr, Rob Jansen. *Network and Distributed System Security*, 2024.

- Overconfidence is a Dangerous Thing: Mitigating Membership Inference Attacks by Enforcing Less Confident Prediction.**[Topic:MIA]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-14-paper.pdf)
  - Zitao Chen, Karthik Pattabiraman. *Network and Distributed System Security*, 2024.

- SigmaDiff: Semantics-Aware Deep Graph Matching for Pseudocode Diffing.**[Topic:DNN]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-208-paper.pdf)
  - Lian Gao, Yu Qu, Sheng Yu, Yue Duan, Heng Yin. *Network and Distributed System Security*, 2024.

- Transpose Attack: Stealing Datasets with Bidirectional Training.**[Topic:数据集窃取]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-325-paper.pdf)
  - Guy Amit, Moshe Levy, Yisroel Mirsky. *Network and Distributed System Security*, 2024.

- A Duty to Forget, a Right to be Assured? Exposing Vulnerabilities in Machine Unlearning Services.**[Topic:MLaaS]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-252-paper.pdf)
  - Hongsheng Hu, Shuo Wang, Jiamin Chang, Haonan Zhong, Ruoxi Sun, Shuang Hao, Haojin Zhu, Minhui Xue. *Network and Distributed System Security*, 2024.

- ActiveDaemon: Unconscious DNN Dormancy and Waking Up via User-specific Invisible Token.**[Topic:Watermark]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-588-paper.pdf)
  - Ge Ren, Gaolei Li, Shenghong Li, Libo Chen, Kui Ren. *Network and Distributed System Security*, 2024.

- Automatic Adversarial Adaption for Stealthy Poisoning Attacks in Federated Learning.**[Topic:FL]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-1366-paper.pdf)
  - Torsten Krauß, Jan König, Alexandra Dmitrienko, Christian Kanzow. *Network and Distributed System Security*, 2024.

- CamPro: Camera-based Anti-Facial Recognition.**[Topic:AFR]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-158-paper.pdf)
  - Wenjun Zhu, Yuan Sun, Jiani Liu, Yushi Cheng, Xiaoyu Ji, Wenyuan Xu. *Network and Distributed System Security*, 2024.

- DeepGo: Predictive Directed Greybox Fuzzing.**[Topic:RL]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-514-paper.pdf)
  - Peihong Lin, Pengfei Wang, Xu Zhou, Wei Xie, Gen Zhang, Kai Lu. *Network and Distributed System Security*, 2024.

- DeGPT: Optimizing Decompiler Output with LLM.**[Topic:LLM]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-401-paper.pdf)
  - Peiwei Hu, Ruigang Liang, Kai Chen. *Network and Distributed System Security*, 2024.

- DEMASQ: Unmasking the ChatGPT Wordsmith.**[Topic:LLM]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-1190-paper.pdf)
  - Kavita Kumari, Alessandro Pegoraro, Hossein Fereidooni, Ahmad-Reza Sadeghi. *Network and Distributed System Security*, 2024.

- Don't Interrupt Me - A Large-Scale Study of On-Device Permission Prompt Quieting in Chrome.**[Topic:ML]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-108-paper.pdf)
  - Marian Harbach, Igor Bilogrevic, Enrico Bacis, Serena Chen, Ravjit Uppal, Andy Paicu, Elias Klim, Meggyn Watkins, Balazs Engedy. *Network and Distributed System Security*, 2024.

- DorPatch: Distributed and Occlusion-Robust Adversarial Patch to Evade Certifiable Defenses.**[Topic:DNN]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-920-paper.pdf)
  - Chaoxiang He, Xiaojing Ma, Bin B. Zhu, Yimiao Zeng, Hanqing Hu, Xiaofan Bai, Hai Jin, Dongmei Zhang. *Network and Distributed System Security*, 2024.

- DRAINCLoG: Detecting Rogue Accounts with Illegally-obtained NFTs using Classifiers Learned on Graphs.**[Topic:DNN]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-888-paper.pdf)
  - Hanna Kim, Jian Cui, Eugene Jang, Chanhee Lee, Yongjae Lee, Jin-Woo Chung, Seungwon Shin. *Network and Distributed System Security*, 2024.

- Flow Correlation Attacks on Tor Onion Service Sessions with Sliding Subset Sum.**[Topic:machine learning classifiers]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-337-paper.pdf)
  - Daniela Lopes, Jin-Dong Dong, Pedro Medeiros, Daniel Castro, Diogo Barradas, Bernardo Portela, João Vinagre, Bernardo Ferreira, Nicolas Christin, Nuno Santos. *Network and Distributed System Security*, 2024.

- FreqFed: A Frequency Analysis-Based Approach for Mitigating Poisoning Attacks in Federated Learning.**[Topic:FL]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-620-paper.pdf)
  - Hossein Fereidooni, Alessandro Pegoraro, Phillip Rieger, Alexandra Dmitrienko, Ahmad-Reza Sadeghi. *Network and Distributed System Security*, 2024.

- Gradient Shaping: Enhancing Backdoor Attack Against Reverse Engineering.**[Topic:Backdoor]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-450-paper.pdf)
  - Rui Zhu, Di Tang, Siyuan Tang, Zihao Wang, Guanhong Tao, Shiqing Ma, XiaoFeng Wang, Haixu Tang. *Network and Distributed System Security*, 2024.

- GraphGuard: Detecting and Counteracting Training Data Misuse in Graph Neural Networks.**[Topic:GNN]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-441-paper.pdf)
  - Bang Wu, He Zhang, Xiangwen Yang, Shuo Wang, Minhui Xue, Shirui Pan, Xingliang Yuan. *Network and Distributed System Security*, 2024.

- Group-based Robustness: A General Framework for Customized Robustness in the Real World.**[Topic:规避攻击]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-84-paper.pdf)
  - Weiran Lin, Keane Lucas, Neo Eyal, Lujo Bauer, Michael K. Reiter, Mahmood Sharif. *Network and Distributed System Security*, 2024.

- Improving the Robustness of Transformer-based Large Language Models with Dynamic Attention.**[Topic:LLM]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-115-paper.pdf)
  - Lujia Shen, Yuwen Pu, Shouling Ji, Changjiang Li, Xuhong Zhang, Chunpeng Ge, Ting Wang. *Network and Distributed System Security*, 2024.

- Large Language Model guided Protocol Fuzzing.**[Topic:LLM]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-556-paper.pdf)
  - Ruijie Meng, Martin Mirchev, Marcel Böhme, Abhik Roychoudhury. *Network and Distributed System Security*, 2024.

- MASTERKEY: Automated Jailbreaking of Large Language Model Chatbots.**[Topic:LLM]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-188-paper.pdf)
  - Gelei Deng, Yi Liu, Yuekang Li, Kailong Wang, Ying Zhang, Zefeng Li, Haoyu Wang, Tianwei Zhang, Yang Liu. *Network and Distributed System Security*, 2024.

- Parrot-Trained Adversarial Examples: Pushing the Practicality of Black-Box Audio Attacks against Speaker Recognition Models.**[Topic:AE]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-545-paper.pdf)
  - Rui Duan, Zhe Qu, Leah Ding, Yao Liu, Zhuo Lu. *Network and Distributed System Security*, 2024.

- Pencil: Private and Extensible Collaborative Learning without the Non-Colluding Assumption.**[Topic:Collaborative Learning]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-512-paper.pdf)
  - Xuanqi Liu, Zhuotao Liu, Qi Li, Ke Xu, Mingwei Xu. *Network and Distributed System Security*, 2024.

- SLMIA-SR: Speaker-Level Membership Inference Attacks against Speaker Recognition Systems.**[Topic:MIA]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-1323-paper.pdf)
  - Guangke Chen, Yedi Zhang, Fu Song. *Network and Distributed System Security*, 2024.

- Sneaky Spikes: Uncovering Stealthy Backdoor Attacks in Spiking Neural Networks with Neuromorphic Data.**[Topic:Backdoor]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-334-paper.pdf)
  - Gorka Abad, Oguzhan Ersoy, Stjepan Picek, Aitor Urbieta. *Network and Distributed System Security*, 2024.

- SSL-WM: A Black-Box Watermarking Approach for Encoders Pre-trained by Self-Supervised Learning.**[Topic:水印]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-374-paper.pdf)
  - Peizhuo Lv, Pan Li, Shenchen Zhu, Shengzhi Zhang, Kai Chen, Ruigang Liang, Chang Yue, Fan Xiang, Yuling Cai, Hualong Ma, Yingjun Zhang, Guozhu Meng. *Network and Distributed System Security*, 2024.

- TextGuard: Provable Defense against Backdoor Attacks on Text Classification.**[Topic:Backdoor]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-90-paper.pdf)
  - Hengzhi Pei, Jinyuan Jia, Wenbo Guo, Bo Li, Dawn Song. *Network and Distributed System Security*, 2024.

- You Can Use But Cannot Recognize: Preserving Visual Privacy in Deep Neural Networks.**[Topic:DNN]**
 [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2024-1361-paper.pdf)
  - Qiushi Li, Yan Zhang, Ju Ren, Qi Li, Yaoxue Zhang. *Network and Distributed System Security*, 2024.

### NDSS'2023

- Fusion: Efficient and Secure Inference Resilient to Malicious Servers. **[Topic: MLaaS]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_s199_paper.pdf)
  - Caiqin Dong, Jian Weng, Jia-Nan Liu, Yue Zhang, Yao Tong, Anjia Yang, Yudan Cheng, Shun Hu. *Network and Distributed System Security*, 2023.

- Machine Unlearning of Features and Labels. **[Topic: Machine-Unlearning]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_s87_paper.pdf)
  - Alexander Warnecke, Lukas Pirch, Christian Wressnegger, Konrad Rieck. *Network and Distributed System Security*, 2023.

- PPA: Preference Profiling Attack Against Federated Learning. **[Topic: FL]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_s171_paper.pdf)
  - Chunyi Zhou, Yansong Gao, Anmin Fu, Kai Chen, Zhiyang Dai, Zhi Zhang, Minhui Xue, Yuqing Zhang. *Network and Distributed System Security*, 2023.

- RoVISQ: Reduction of Video Service Quality via Adversarial Attacks on Deep Learning-based Video Compression. **[Topic: AEs]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_s165_paper.pdf)
  - Jung-Woo Chang, Mojan Javaheripi, Seira Hidano, Farinaz Koushanfar. *Network and Distributed System Security*, 2023.

- Securing Federated Sensitive Topic Classification against Poisoning Attacks. **[Topic: FL]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_s112_paper.pdf)
  - Tianyue Chu, Alvaro Garcia-Recuero, Costas Iordanou, Georgios Smaragdakis, Nikolaos Laoutaris. *Network and Distributed System Security*, 2023.

- The “Beatrix” Resurrections: Robust Backdoor Detection via Gram Matrices. **[Topic: Backdoor]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_s69_paper.pdf)
  - Wanlun Ma, Derui Wang, Ruoxi Sun, Minhui Xue, Sheng Wen, Yang Xiang. *Network and Distributed System Security*, 2023.

- Adversarial Robustness for Tabular Data through Cost and Utility Awareness. **[Topic: AEs]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_f924_paper.pdf)
  - Klim Kireev, Bogdan Kulynych, Carmela Troncoso. *Network and Distributed System Security*, 2023. 

- Backdoor Attacks Against Dataset Distillation. **[Topic: Backdoor]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_f287_paper.pdf)
  - Yugeng Liu, Zheng Li, Michael Backes, Yun Shen, Yang Zhang. *Network and Distributed System Security*, 2023. 

- BEAGLE: Forensics of Deep Learning Backdoor Attack for Better Defense. **[Topic: Backdoor]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_f944_paper.pdf)
  - Siyuan Cheng, Guanhong Tao, Yingqi Liu, Shengwei An, Xiangzhe Xu, Shiwei Feng, Guangyu Shen, Kaiyuan Zhang, Qiuling Xu, Shiqing Ma, Xiangyu Zhang. *Network and Distributed System Security*, 2023. 

- Focusing on Pinocchio's Nose: A Gradients Scrutinizer to Thwart Split-Learning Hijacking Attacks Using Intrinsic Attributes. **[Topic: SL]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_f874_paper.pdf)
  - Jiayun Fu, Xiaojing Ma, Bin B. Zhu, Pingyi Hu, Ruixin Zhao, Yaru Jia, Peng Xu, Hai Jin, Dongmei Zhang. *Network and Distributed System Security*, 2023. 

- REaaS: Enabling Adversarially Robust Downstream Classifiers via Robust Encoder as a Service. **[Topic: AEs]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2023/02/ndss2023_f444_paper.pdf)
  - Wenjie Qu, Jinyuan Jia, Neil Zhenqiang Gong. *Network and Distributed System Security*, 2023. 

### NDSS'2022

- DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspection. **[Topic: Backdoor]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2022-156-paper.pdf)
  - Phillip Rieger, Thien Duc Nguyen, Markus Miettinen, Ahmad-Reza Sadeghi. *Network and Distributed System Security*, 2022. 

- FedCRI: Federated Mobile Cyber-Risk Intelligence. **[Topic: FL]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2022-153-paper.pdf)
  - Hossein Fereidooni, Alexandra Dmitrienko, Phillip Rieger, Markus Miettinen, Ahmad-Reza Sadeghi, Felix Madlener. *Network and Distributed System Security*, 2022. 

- Get a Model! Model Hijacking Attack Against Machine Learning Models. **[Topic: Model-Hijacking]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2022-64-paper.pdf)
  - Ahmed Salem, Michael Backes, Yang Zhang. *Network and Distributed System Security*, 2022. 

- Local and Central Differential Privacy for Robustness and Privacy in Federated Learning. **[Topic: FL]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2022-54-paper.pdf)
  - Mohammad Naseri, Jamie Hayes, Emiliano De Cristofaro. *Network and Distributed System Security*, 2022. 

- Property Inference Attacks Against GANs. **[Topic: IA & GAN]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2022-19-paper.pdf)
  - Junhao Zhou, Yufei Chen, Chao Shen, Yang Zhang. *Network and Distributed System Security*, 2022. 

- ATTEQ-NN: Attention-based QoE-aware Evasive Backdoor Attacks. **[Topic: Backdoor]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2022-12-paper.pdf)
  - Xueluan Gong, Yanjiao Chen, Jianshuo Dong, Qian Wang. *Network and Distributed System Security*, 2022. 

- Fooling the Eyes of Autonomous Vehicles: Robust Physical Adversarial Examples Against Traffic Sign Recognition Systems. **[Topic: AEs]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2022-130-paper.pdf)
  - Wei Jia, Zhaojun Lu, Haichun Zhang, Zhenglin Liu, Jie Wang, Gang Qu. *Network and Distributed System Security*, 2022. 

- MIRROR: Model Inversion for Deep Learning Network with High Fidelity. **[Topic: MIA]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2022-335-paper.pdf)
  - Shengwei An, Guanhong Tao, Qiuling Xu, Yingqi Liu, Guangyu Shen, Yuan Yao, Jingwei Xu, Xiangyu Zhang. *Network and Distributed System Security*, 2022. 

- RamBoAttack: A Robust and Query Efficient Deep Neural Network Decision Exploit. **[Topic: AEs]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/2022-200-paper.pdf)
  - Viet Quoc Vo, Ehsan Abbasnejad, Damith C. Ranasinghe. *Network and Distributed System Security*, 2022. 


### NDSS'2021

- Data Poisoning Attacks to Deep Learning Based Recommender Systems. **[Topic: PAs]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/ndss2021_6C-4_24525_paper.pdf)
  - Hai Huang, Jiaming Mu, Neil Zhenqiang Gong, Qi Li, Bin Liu, Mingwei Xu. *Network and Distributed System Security*, 2021. 

- FLTrust: Byzantine-robust Federated Learning via Trust Bootstrapping. **[Topic: PA & FL]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/ndss2021_6C-2_24434_paper.pdf)
  - Xiaoyu Cao, Minghong Fang, Jia Liu, Neil Zhenqiang Gong. *Network and Distributed System Security*, 2021. 

- Manipulating the Byzantine: Optimizing Model Poisoning Attacks and Defenses for Federated Learning. **[Topic: PA & FL]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/ndss2021_6C-3_24498_paper.pdf)
  - Virat Shejwalkar, Amir Houmansadr. *Network and Distributed System Security*, 2021. 

- Practical Blind Membership Inference Attack via Differential Comparisons. **[Topic: MIA]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/ndss2021_5C-2_24293_paper.pdf)
  - Bo Hui, Yuchen Yang, Haolin Yuan, Philippe Burlina, Neil Zhenqiang Gong, Yinzhi Cao. *Network and Distributed System Security*, 2021. 

- POSEIDON: Privacy-Preserving Federated Neural Network Learning. **[Topic: FL]**
  [[pdf]](https://www.ndss-symposium.org/wp-content/uploads/ndss2021_6C-1_24119_paper.pdf)
  - Sinem Sav, Apostolos Pyrgelis, Juan Ramón Troncoso-Pastoriza, David Froelicher, Jean-Philippe Bossuat, Joao Sa Sousa, Jean-Pierre Hubaux. *Network and Distributed System Security*, 2021.

## Papers in USENIX Security 

### USENIX Security '2024

- AttackGNN: Red-Teaming GNNs in Hardware Security Using Reinforcement Learning.**[Topic:GNN&RL]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-gohil.pdf)
  - Vasudev Gohil, Satwik Patnaik, Dileep Kalathil, Jeyavijayan Rajendran. *USENIX Security*, 2024.

- INSIGHT: Attacking Industry-Adopted Learning Resilient Logic Locking Techniques Using Explainable Graph Neural Network.**[Topic:ML]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-mankali.pdf)
  - Lakshmi Likhitha Mankali, Ozgur Sinanoglu, Satwik Patnaik. *USENIX Security*, 2024.

- FAMOS: Robust Privacy-Preserving Authentication on Payment Apps via Federated Multi-Modal Contrastive Learning.**[Topic:FL]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-cai-yifeng.pdf)
  - Yifeng Cai, Ziqi Zhang, Jiaping Gui, Bingyan Liu, Xiaoke Zhao, Ruoyu Li, Zhe Li, Ding Li. *USENIX Security*, 2024.

- Efficient Privacy Auditing in Federated Learning.**[Topic:FL]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-chang.pdf)
  - Hongyan Chang, Brandon Edwards, Anindya S. Paul, Reza Shokri. *USENIX Security*, 2024.

- Defending Against Data Reconstruction Attacks in Federated Learning: An Information Theory Approach.**[Topic:FL]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-tan.pdf)
  - Qi Tan, Qi Li, Yi Zhao, Zhuotao Liu, Xiaobing Guo, Ke Xu. *USENIX Security*, 2024.

- Lotto: Secure Participant Selection against Adversarial Servers in Federated Learning.**[Topic:FL]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-jiang-zhifeng.pdf)
  - Zhifeng Jiang, Peng Ye, Shiqi He, Wei Wang, Ruichuan Chen, Bo Li. *USENIX Security*, 2024.

- KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection.**[Topic:LLM for Security]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-li-yuexin.pdf)
  - Yuexin Li, Chengyu Huang, Shumin Deng, Mei Lin Lock, Tri Cao, Nay Oo, Hoon Wei Lim, Bryan Hooi. *USENIX Security*, 2024.

- Exploring ChatGPT's Capabilities on Vulnerability Management.**[Topic:LLM for Security]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-liu-peiyu.pdf)
  - Peiyu Liu, Junming Liu, Lirong Fu, Kangjie Lu, Yifan Xia, Xuhong Zhang, Wenzhi Chen, Haiqin Weng, Shouling Ji, Wenhai Wang. *USENIX Security*, 2024.

- Large Language Models for Code Analysis: Do LLMs Really Do Their Job?**[Topic:LLM for Security]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-fang.pdf)
  - Chongzhou Fang, Ning Miao, Shaurya Srivastav, Jialin Liu, Ruoyu Zhang, Ruijie Fang, Asmita, Ryan Tsang, Najmeh Nazari, Han Wang, Houman Homayoun. *USENIX Security*, 2024.

- PentestGPT: Evaluating and Harnessing Large Language Models for Automated Penetration Testing.**[Topic:LLM for Security]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-deng.pdf)
  - Gelei Deng, Yi Liu, Víctor Mayoral Vilches, Peng Liu, Yuekang Li, Yuan Xu, Martin Pinzger, Stefan Rass, Tianwei Zhang, Yang Liu. *USENIX Security*, 2024.

- Fuzzing BusyBox: Leveraging LLM and Crash Reuse for Embedded Bug Unearthing.**[Topic:LLM]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-asmita.pdf)
  - Asmita, Yaroslav Oliinyk, Michael Scott, Ryan Tsang, Chongzhou Fang, Houman Homayoun. *USENIX Security*, 2024.

- DNN-GP: Diagnosing and Mitigating Model's Faults Using Latent Concepts.**[Topic:DNN]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-wang-shuo.pdf)
  - Shuo Wang, Hongsheng Hu, Jiamin Chang, Benjamin Zi Hao Zhao, Qi Alfred Chen, Minhui Xue. *USENIX Security*, 2024.

- Yes, One-Bit-Flip Matters! Universal DNN Model Inference Depletion with Runtime Code Fault Injection.**[Topic:DNN]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-li-shaofeng.pdf)
  - Shaofeng Li, Xinyu Wang, Minhui Xue, Haojin Zhu, Zhi Zhang, Yansong Gao, Wen Wu, Xuemin (Sherman) Shen. *USENIX Security*, 2024.

- Tossing in the Dark: Practical Bit-Flipping on Gray-box Deep Neural Networks for Runtime Trojan Injection.**[Topic:DNN]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-wang-zihao-tossing.pdf)
  - Zihao Wang, Di Tang, XiaoFeng Wang, Wei He, Zhaoyang Geng, Wenhao Wang. *USENIX Security*, 2024.

- Forget and Rewire: Enhancing the Resilience of Transformer-based Models against Bit-Flip Attacks.**[Topic:DNN]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-nazari.pdf)
  - Najmeh Nazari, Hosein Mohammadi Makrani, Chongzhou Fang, Hossein Sayadi, Setareh Rafatirad, Khaled N. Khasawneh, Houman Homayoun. *USENIX Security*, 2024.

- Automated Large-Scale Analysis of Cookie Notice Compliance.**[Topic:ML for Security]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-bouhoula.pdf)
  - Ahmed Bouhoula, Karel Kubicek, Amit Zac, Carlos Cotrini, David A. Basin. *USENIX Security*, 2024.

- Detecting and Mitigating Sampling Bias in Cybersecurity with Unlabeled Data.**[Topic:ML for Security]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-thirumuruganathan_1.pdf)
  - Saravanan Thirumuruganathan, Fatih Deniz, Issa Khalil, Ting Yu, Mohamed Nabeel, Mourad Ouzzani. *USENIX Security*, 2024.

- An LLM-Assisted Easy-to-Trigger Backdoor Attack on Code Completion Models: Injecting Disguised Vulnerabilities against Strong Detection.**[Topic:LLM]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-yan.pdf)
  - Shenao Yan, Shen Wang, Yue Duan, Hanbin Hong, Kiho Lee, Doowon Kim, Yuan Hong. *USENIX Security*, 2024.

- REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative Large Language Models.**[Topic:LLM]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-zhang-ruisi.pdf)
  - Ruisi Zhang, Shehzeen Samarah Hussain, Paarth Neekhara, Farinaz Koushanfar. *USENIX Security*, 2024.

- Formalizing and Benchmarking Prompt Injection Attacks and Defenses.**[Topic:LLM]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-liu-yupei.pdf)
  - Yupei Liu, Yuqi Jia, Runpeng Geng, Jinyuan Jia, Neil Zhenqiang Gong. *USENIX Security*, 2024.

- Instruction Backdoor Attacks Against Customized LLMs.**[Topic:LLM]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-zhang-rui.pdf)
  - Rui Zhang, Hongwei Li, Rui Wen, Wenbo Jiang, Yuan Zhang, Michael Backes, Yun Shen, Yang Zhang. *USENIX Security*, 2024.

- AutoFHE: Automated Adaption of CNNs for Efficient Evaluation over FHE.**[Topic:CNN]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-ao.pdf)
  - Wei Ao, Vishnu Naresh Boddeti. *USENIX Security*, 2024.

- Fast and Private Inference of Deep Neural Networks by Co-designing Activation Functions.**[Topic:MLaaS]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-diaa.pdf)
  - Abdulrahman Diaa, Lucas Fenaux, Thomas Humphries, Marian Dietz, Faezeh Ebrahimianghazani, Bailey Kacsmar, Xinda Li, Nils Lukas, Rasoul Akhavan Mahdavi, Simon Oya, Ehsan Amjadian, Florian Kerschbaum. *USENIX Security*, 2024.

- OblivGNN: Oblivious Inference on Transductive and Inductive Graph Neural Network.**[Topic:GNN]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-xu-zhibo.pdf)
  - Zhibo Xu, Shangqi Lai, Xiaoning Liu, Alsharif Abuadbba, Xingliang Yuan, Xun Yi. *USENIX Security*, 2024.

- MD-ML: Super Fast Privacy-Preserving Machine Learning for Malicious Security with a Dishonest Majority.**[Topic:PPML]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-yuan.pdf)
  - Boshi Yuan, Shixuan Yang, Yongxiang Zhang, Ning Ding, Dawu Gu, Shi-Feng Sun. *USENIX Security*, 2024.

- Accelerating Secure Collaborative Machine Learning with Protocol-Aware RDMA.**[Topic:SCML]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-ren.pdf)
  - Zhenghang Ren, Mingxuan Fan, Zilong Wang, Junxue Zhang, Chaoliang Zeng, Zhicong Huang, Cheng Hong, Kai Chen. *USENIX Security*, 2024.

- Did the Neurons Read your Book? Document-level Membership Inference for Large Language Models.**[Topic:LLM]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-meeus.pdf)
  - Matthieu Meeus, Shubham Jain, Marek Rei, Yves-Alexandre de Montjoye. *USENIX Security*, 2024.

- MIST: Defending Against Membership Inference Attacks Through Membership-Invariant Subspace Training.**[Topic:MI attack]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-li-jiacheng.pdf)
  - Jiacheng Li, Ninghui Li, Bruno Ribeiro. *USENIX Security*, 2024.

- Neural Network Semantic Backdoor Detection and Mitigation: A Causality-Based Approach.**[Topic:Backdoor]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-sun-bing.pdf)
  - Bing Sun, Jun Sun, Wayne Koh, Jie Shi. *USENIX Security*, 2024.

- On the Difficulty of Defending Contrastive Learning against Backdoor Attacks.**[Topic:Backdoor]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-li-changjiang.pdf)
  - Changjiang Li, Ren Pang, Bochuan Cao, Zhaohan Xi, Jinghui Chen, Shouling Ji, Ting Wang. *USENIX Security*, 2024.

- Mudjacking: Patching Backdoor Vulnerabilities in Foundation Models.**[Topic:Backdoor]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-liu-hongbin.pdf)
  - Hongbin Liu, Michael K. Reiter, Neil Zhenqiang Gong. *USENIX Security*, 2024.

- Xplain: Analyzing Invisible Correlations in Model Explanation.**[Topic:Backdoor]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-kumari.pdf)
  - Kavita Kumari, Alessandro Pegoraro, Hossein Fereidooni, Ahmad-Reza Sadeghi. *USENIX Security*, 2024.

- Verify your Labels! Trustworthy Predictions and Datasets via Confidence Scores.**[Topic:Backdoor]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-krauss-verify_1.pdf)
  - Torsten Krauß, Jasper Stang, Alexandra Dmitrienko. *USENIX Security*, 2024.

- More Simplicity for Trainers, More Opportunity for Attackers: Black-Box Attacks on Speaker Recognition Systems by Inferring Feature Extractor.**[Topic:AE]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-ge-attacks.pdf)
  - Yunjie Ge, Pinji Chen, Qian Wang, Lingchen Zhao, Ningping Mou, Peipei Jiang, Cong Wang, Qi Li, Chao Shen. *USENIX Security*, 2024.

- Adversarial Illusions in Multi-Modal Embeddings.**[Topic:Multi-modal embeddings]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-zhang-tingwei.pdf)
  - Tingwei Zhang, Rishi D. Jha, Eugene Bagdasaryan, Vitaly Shmatikov. *USENIX Security*, 2024.

- Splitting the Difference on Adversarial Training.**[Topic:Adversarial Attack Defense]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-levi.pdf)
  - Matan Levi, Aryeh Kontorovich. *USENIX Security*, 2024.

- Machine Learning needs Better Randomness Standards: Randomised Smoothing and PRNG-based attacks.**[Topic:Adversarial Attack Defense]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-dahiya.pdf)
  - Pranav Dahiya, Ilia Shumailov, Ross Anderson. *USENIX Security*, 2024.

- Lurking in the shadows: Unveiling Stealthy Backdoor Attacks against Personalized Federated Learning.**[Topic:Backdoor and Federated Learning]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-lyu.pdf)
  - Xiaoting Lyu, Yufei Han, Wei Wang, Jingkai Liu, Yongsheng Zhu, Guangquan Xu, Jiqiang Liu, Xiangliang Zhang. *USENIX Security*, 2024.

- ACE: A Model Poisoning Attack on Contribution Evaluation Methods in Federated Learning.**[Topic:Backdoor and Federated Learning]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-xu-zhangchen.pdf)
  - Zhangchen Xu, Fengqing Jiang, Luyao Niu, Jinyuan Jia, Bo Li, Radha Poovendran. *USENIX Security*, 2024.

- BackdoorIndicator: Leveraging OOD Data for Proactive Backdoor Detection in Federated Learning.**[Topic:Backdoor and Federated Learning]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-li-songze.pdf)
  - Songze Li, Yanbo Dai. *USENIX Security*, 2024.

- UBA-Inf: Unlearning Activated Backdoor Attack with Influence-Driven Camouflage.**[Topic:Backdoor and Federated Learning]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-huang-zirui.pdf)
  - Zirui Huang, Yunlong Mao, Sheng Zhong. *USENIX Security*, 2024.

- LLM-Fuzzer: Scaling Assessment of Large Language Model Jailbreaks.**[Topic:LLM Jailbreaking]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-yu-jiahao.pdf)
  - Jiahao Yu, Xingwei Lin, Zheng Yu, Xinyu Xing. *USENIX Security*, 2024.

- Don't Listen To Me： Understanding and exploring jailbreak prompts of large language models.**[Topic:LLM Jailbreaking]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-yu-zhiyuan.pdf)
  - Zhiyuan Yu， Xiaogeng Liu， Shunning Liang， Zach Cameron， Chaowei Xiao， Ning Zhang. *USENIX Security*, 2024.

- Making Them Ask and Answer: Jailbreaking Large Language Models in Few Queries via Disguise and Reconstruction.**[Topic:LLM Jailbreaking]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-liu-tong.pdf)
  - Tong Liu, Yingjie Zhang, Zhe Zhao, Yinpeng Dong, Guozhu Meng, Kai Chen. *USENIX Security*, 2024.

- SoK: All You Need to Know About On-Device ML Model Extraction - The Gap Between Research and Practice.**[Topic:Watermark]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-nayan.pdf)
  - Tushar Nayan, Qiming Guo, Mohammed Alduniawi, Marcus Botacin, A. Selcuk Uluagac, Ruimin Sun. *USENIX Security*, 2024.

- Unveiling the Secrets without Data: Can Graph Neural Networks Be Exploited through Data-Free Model Extraction Attacks?**[Topic:GNN]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-zhuang.pdf)
  - Yuanxin Zhuang, Chuan Shi, Mengmei Zhang, Jinghui Chen, Lingjuan Lyu, Pan Zhou, Lichao Sun. *USENIX Security*, 2024.

- ClearStamp: A Human-Visible and Robust Model-Ownership Proof based on Transposed Model Training.**[Topic:Watermark]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-krauss-clearstamp.pdf)
  - Torsten Krauß, Jasper Stang, Alexandra Dmitrienko. *USENIX Security*, 2024.

- DeepEclipse: How to Break White-Box DNN-Watermarking Schemes.**[Topic:Watermark]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-pegoraro.pdf)
  - Alessandro Pegoraro, Carlotta Segna, Kavita Kumari, Ahmad-Reza Sadeghi. *USENIX Security*, 2024.

- Deciphering Textual Authenticity: A Generalized Strategy through the Lens of Large Language Semantics for Detecting Human vs. Machine-Generated Text.**[Topic:LLM]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-bethany.pdf)
  - Mazal Bethany, Brandon Wherry, Emet Bethany, Nishant Vishwamitra, Anthony Rios, Peyman Najafirad. *USENIX Security*, 2024.

- How Does a Deep Learning Model Architecture Impact Its Privacy? A Comprehensive Study of Privacy Attacks on CNNs and Transformers.**[Topic:Privacy Attacks]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-zhang-guangsheng.pdf)
  - Guangsheng Zhang, Bo Liu, Huan Tian, Tianqing Zhu, Ming Ding, Wanlei Zhou. *USENIX Security*, 2024.

- FaceObfuscator: Defending Deep Learning-based Privacy Attacks with Gradient Descent-resistant Features in Face Recognition.**[Topic:Privacy Attacks]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-jin-shuaifan.pdf)
  - Shuaifan Jin, He Wang, Zhibo Wang, Feng Xiao, Jiahui Hu, Yuan He, Wenwen Zhang, Zhongjie Ba, Weijie Fang, Shuhong Yuan, Kui Ren. *USENIX Security*, 2024.

- Hijacking Attacks against Neural Network by Analyzing Training Data.**[Topic:Hijacking Attacks]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-ge-hijacking.pdf)
  - Yunjie Ge, Qian Wang, Huayang Huang, Qi Li, Cong Wang, Chao Shen, Lingchen Zhao, Peipei Jiang, Zheng Fang, Shenyi Zhang. *USENIX Security*, 2024.

- Information Flow Control in Machine Learning through Modular Model Architecture.**[Topic:ML]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-tiwari.pdf)
  - Trishita Tiwari, Suchin Gururangan, Chuan Guo, Weizhe Hua, Sanjay Kariyappa, Udit Gupta, Wenjie Xiong, Kiwan Maeng, Hsien-Hsin S. Lee, G. Edward Suh. *USENIX Security*, 2024.

- Devil in the Room: Triggering Audio Backdoors in the Physical World.**[Topic:Physical Adversarial Attacks]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-chen-meng.pdf)
  - Meng Chen, Xiangyu Xu, Li Lu, Zhongjie Ba, Feng Lin, Kui Ren. *USENIX Security*, 2024.

- FraudWhistler: A Resilient, Robust and Plug-and-play Adversarial Example Detection Method for Speaker Recognition.**[Topic:AE]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-wang-kun.pdf)
  - Kun Wang, Xiangyu Xu, Li Lu, Zhongjie Ba, Feng Lin, Kui Ren. *USENIX Security*, 2024.

- EaTVul: ChatGPT-based Evasion Attack Against Software Vulnerability Detection.**[Topic:Evasion Attack]**
 [[pdf]](https://www.usenix.org/system/files/usenixsecurity24-liu-shigang.pdf)
  - Shigang Liu, Di Cao, Junae Kim, Tamas Abraham, Paul Montague, Seyit Camtepe, Jun Zhang, Yang Xiang. *USENIX Security*, 2024.

### USENIX Security '2023

- “Security is not my field, I’m a stats guy”: A Qualitative Root Cause Analysis of Barriers to Adversarial Machine Learning Defenses in Industry. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-324-mink.pdf)
  - Jaron Mink, Harjot Kaur, Juliane Schmüser and Sascha Fahl, Yasemin Acar. *USENIX Security*, 2023. 

- A Data-free Backdoor Injection Approach in Neural Networks. **[Topic: Backdoor]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-573-lv.pdf)
  - Peizhuo Lv, Chang Yue, Ruigang Liang, Yunfei Yang. *USENIX Security*, 2023. 

- A Plot is Worth a Thousand Words: Model Information Stealing Attacks via Scientific Plots. **[Topic: MSA]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-28-zhang-boyang.pdf)
  - Boyang Zhang, Xinlei He, Yun Shen, Tianhao Wang, Yang Zhang. *USENIX Security*, 2023. 

- Aegis: Mitigating Targeted Bit-flip Attacks against Deep Neural Networks. **[Topic: BFA]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-246-wang-jialai.pdf)
  - Jialai Wang, Ziyuan Zhang, Meiqi Wang, Han Qiu, Tianwei Zhang, Qi Li, Zongpeng Li, Tao Wei, Chao Zhang. *USENIX Security*, 2023. 

- Black-box Adversarial Example Attack towards FCG Based Android Malware Detection under Incomplete Feature Information. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-2-li-heng.pdf)
  - Heng Li, Zhang Cheng, Bang Wu, Liheng Yuan, Cuiying Gao, Wei Yuan, Xiapu Luo. *USENIX Security*, 2023. 

- CAPatch: Physical Adversarial Patch against Image Captioning Systems. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-121-zhang-shibo.pdf)
  - Shibo Zhang, Yushi Cheng, Wenjun Zhu, Xiaoyu Ji, Wenyuan Xu. *USENIX Security*, 2023. 

- DiffSmooth: Certifiably Robust Learning via Diffusion Models and Local Smoothing. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-540-zhang-jiawei.pdf)
  - Jiawei Zhang, Zhongzhu Chen, Huan Zhang, Chaowei Xiao, Bo Li. *USENIX Security*, 2023.

- Every Vote Counts: Ranking-Based Training of Federated Learning to Resist Poisoning Attacks. **[Topic: PA & FL]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-475-mozaffari.pdf)
  - Hamid Mozaffari, Virat Shejwalkar, Amir Houmansadr. *USENIX Security*, 2023. 

- Exorcising "Wraith": Protecting LiDAR-based Object Detector in Automated Driving System from Appearing Attacks. **[Topic: Appearing-Attack]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-190-xiao-qifan.pdf)
  - Qifan Xiao, Xudong Pan, Yifan Lu, Mi Zhang, Jiarun Dai, Min Yang. *USENIX Security*, 2023.  

- Fine-grained Poisoning Attack to Local Differential Privacy Protocols for Mean and Variance Estimation. **[Topic: DP]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-421-li-xiaoguang.pdf)
  - Xiaoguang Li, Ninghui Li, Wenhai Sun,  Neil Zhenqiang Gong, Hui Li. *USENIX Security*, 2023. 

- FreeEagle: Detecting Complex Neural Trojans in Data-Free Cases. **[Topic: Backdoor]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-85-fu-chong.pdf)
  - Chong Fu, Xuhong Zhang, Shouling Ji, Ting Wang, Peng Lin, Yanghe Feng, Jianwei Yin. *USENIX Security*, 2023. 

- GAP: Differentially Private Graph Neural Networks with Aggregation Perturbation. **[Topic: DP & GNN]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-196-sajadmanesh.pdf)
  - Sina Sajadmanesh, Ali Shahin Shamsabadi, Aurélien Bellet, Daniel Gatica-Perez. *USENIX Security*, 2023. 

- Lost at C: A User Study on the Security Implications of Large Language Model Code Assistants. **[Topic: LLM]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-353-sandoval.pdf)
  - Gustavo Sandoval, Hammond Pearce, Teo Nys, Ramesh Karri, Siddharth Garg, Brendan Dolan-Gavitt. *USENIX Security*, 2023. 

- Meta-Sift: How to Sift Out a Clean Subset in the Presence of Data Poisoning?. **[Topic: PA]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-99-zeng-yi.pdf)
  - Yi Zeng, Minzhou Pan, Himanshu Jahagirdar, Ming Jin, Lingjuan Lyu, Ruoxi Jia. *USENIX Security*, 2023. 

- No more Reviewer #2: Subverting Automatic Paper-Reviewer Assignment using Adversarial Learning. **[Topic: AEs]**
  [[pdf]](https://arxiv.org/pdf/2303.14443.pdf)
  - Thorsten Eisenhofer, Erwin Quiring, Jonas Möller, Doreen Riepel, Thorsten Holz, Konrad Rieck. *USENIX Security*, 2023. 

- PELICAN: Exploiting Backdoors of Naturally Trained Deep Learning Models In Binary Code Analysis. **[Topic: Backdoor]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-493-zhang-zhuo.pdf)
  - Zhuo Zhang, Guanhong Tao, Guangyu Shen, Shengwei An, Qiuling Xu, Yingqi Liu, Yapeng Ye, Yaoxuan Wu, Xiangyu Zhang. *USENIX Security*, 2023. 

- PrivateFL: Accurate, Differentially Private Federated Learning via Personalized Data Transformation. **[Topic: DP & FL]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-427-yang-yuchen.pdf)
  - Yuchen Yang, Bo Hui, Haolin Yuan, Neil Gong, Yinzhi Cao. *USENIX Security*, 2023. 

- Rethinking White-Box Watermarks on Deep Learning Models under Neural Structural Obfuscation. **[Topic: Watermark]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-444-yan-yifan.pdf)
  - Yifan Yan, Xudong Pan, Mi Zhang, and Min Yang. *USENIX Security*, 2023. 

- X-Adv: Physical Adversarial Object Attacks against X-ray Prohibited Item Detection. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23fall-prepub-34-liu-aishan.pdf)
  - Aishan Liu, Jun Guo, Jiakai Wang, Siyuan Liang, Renshuai Tao, Wenbo Zhou, Cong Liu, Xianglong Liu. *USENIX Security*, 2023. 

- TPatch: A Triggered Physical Adversarial Patch. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_123-zhu-prepub.pdf)
  - Wenjun Zhu, Xiaoyu Ji, Yushi Cheng, Shibo Zhang, Wenyuan Xu. *USENIX Security*, 2023.  

- UnGANable: Defending Against GAN-based Face Manipulation. **[Topic: Deepfake]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_136-li_zheng-prepub.pdf)
  - WZheng Li, Ning Yu, Ahmed Salem, Michael Backes, Mario Fritz, Yang Zhang. *USENIX Security*, 2023. 

- Squint Hard Enough: Attacking Perceptual Hashing with Adversarial Machine Learning. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_146-prokos-prepub.pdf)
  - Jonathan Prokos, Neil Fendley, Matthew Green, Roei Schuster, Eran Tromer, Tushar Jois, Yinzhi Cao. *USENIX Security*, 2023. 

- The Space of Adversarial Strategies. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_256-sheatsley-prepub.pdf)
  - Ryan Sheatsley, Blaine Hoak, Eric Pauley, Patrick McDaniel. *USENIX Security*, 2023. 

- That Person Moves Like A Car: Misclassification Attack Detection for Autonomous Systems Using Spatiotemporal Consistency. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_278-man-prepub.pdf)
  - Yanmao Man, Raymond Muller, Ming Li, Z. Berkay Celik, Ryan Gerdes. *USENIX Security*, 2023. 

- NeuroPots: Realtime Proactive Defense against Bit-Flip Attacks in Neural Networks. **[Topic: BFA]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_334-liu_qi-prepub.pdf)
  - Qi Liu, Jieming Yin, Wujie Wen, Chengmo Yang, Shi Sha. *USENIX Security*, 2023. 

- URET: Universal Robustness Evaluation Toolkit (for Evasion). **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_347-eykholt-prepub.pdf)
  - Kevin Eykholt, Taesung Lee, Douglas Schales, Jiyong Jang, Ian Molloy, Masha Zorin. *USENIX Security*, 2023. 

- SMACK: Semantically Meaningful Adversarial Audio Attack. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_371-yu_zhiyuan-prepub.pdf)
  - Zhiyuan Yu, Yuanhaur Chang, Ning Zhang, Chaowei Xiao. *USENIX Security*, 2023. 

- Gradient Obfuscation Gives a False Sense of Security in Federated Learning. **[Topic: FL]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_372-yue-prepub.pdf)
  - Kai Yue, Richeng Jin, Chau-Wai Wong, Dror Baron, Huaiyu Dai. *USENIX Security*, 2023. 

- Fairness Properties of Face Recognition and Obfuscation Systems. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_388-rosenberg-prepub.pdf)
  - Harrison Rosenberg, Brian Tang, Kassem Fawaz, Somesh Jha. *USENIX Security*, 2023. 

- PCAT: Functionality and Data Stealing from Split Learning by Pseudo-Client Attack. **[Topic: SL]**
  [[pdf]](https://www.usenix.org/system/files/sec23summer_445-gao-prepub.pdf)
  - Xinben Gao, Lan Zhang. *USENIX Security*, 2023. 

### USENIX Security '2022

- ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine Learning Models. **[Topic: MIA]**
  [[pdf]](https://www.usenix.org/system/files/sec22-liu-yugeng.pdf)
  - Yugeng Liu, Rui Wen, Xinlei He, Ahmed Salem, Zhikun Zhang, Michael Backes, Emiliano De Cristofaro, Mario Fritz, Yang Zhang. *USENIX Security*, 2022. 

- Blacklight: Scalable Defense for Neural Networks against Query-Based Black-Box Attacks. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec22-li-huiying.pdf)
  - Huiying Li, Shawn Shan, Emily Wenger, Jiayun Zhang, Haitao Zheng, Ben Y. Zhao. *USENIX Security*, 2022. 

- AutoDA: Automated Decision-based Iterative Adversarial Attacks. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec22-fu-qi.pdf)
  - Qi-An Fu, Yinpeng Dong, Hang Su, Jun Zhu, Chao Zhang. *USENIX Security*, 2022. 

- Poison Forensics: Traceback of Data Poisoning Attacks in Neural Networks. **[Topic: PA]**
  [[pdf]](https://www.usenix.org/system/files/sec22-shan.pdf)
  - Shawn Shan, Arjun Nitin Bhagoji, Haitao Zheng, Ben Y. Zhao. *USENIX Security*, 2022. 

- Teacher Model Fingerprinting Attacks Against Transfer Learning. **[Topic: Fingerprinting]**
  [[pdf]](https://www.usenix.org/system/files/sec22-chen-yufei.pdf)
  - Yufei Chen, Chao Shen, Cong Wang, Yang Zhang. *USENIX Security*, 2022. 

- Hidden Trigger Backdoor Attack on NLP Models via Linguistic Style Manipulation. **[Topic: Backdoor]**
  [[pdf]](https://www.usenix.org/system/files/sec22-pan-hidden.pdf)
  - Xudong Pan, Mi Zhang, Beina Sheng, Jiaming Zhu, Min Yang. *USENIX Security*, 2022. 

- PoisonedEncoder: Poisoning the Unlabeled Pre-training Data in Contrastive Learning. **[Topic: PA]**
  [[pdf]](https://www.usenix.org/system/files/sec22-liu-hongbin.pdf)
  - Hongbin Liu, Jinyuan Jia, Neil Zhenqiang Gong. *USENIX Security*, 2022. 

- Pool Inference Attacks on Local Differential Privacy: Quantifying the Privacy Guarantees of Apple's Count Mean Sketch in Practice. **[Topic: IA & DP]**
  [[pdf]](https://www.usenix.org/system/files/sec22-gadotti_1.pdf)
  - Andrea Gadotti, Florimond Houssiau, Meenatchi Sundaram Muthu Selva Annamalai, Yves-Alexandre de Montjoye. *USENIX Security*, 2022. 

- PatchCleanser: Certifiably Robust Defense against Adversarial Patches for Any Image Classifier. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec22-xiang.pdf)
  - Chong Xiang, Saeed Mahloujifar, Prateek Mittal. *USENIX Security*, 2022. 

- Exploring the Security Boundary of Data Reconstruction via Neuron Exclusivity Analysis. **[Topic: DRA]**
  [[pdf]](https://www.usenix.org/system/files/sec22-pan-exploring.pdf)
  - Xudong Pan, Mi Zhang, Yifan Yan, Jiaming Zhu, Min Yang. *USENIX Security*, 2022. 

- Poisoning Attacks to Local Differential Privacy Protocols for Key-Value Data. **[Topic: PA & DP]**
  [[pdf]](https://www.usenix.org/system/files/sec22-wu-yongji.pdf)
  - Yongji Wu, Xiaoyu Cao, Jinyuan Jia, Neil Zhenqiang Gong. *USENIX Security*, 2022. 

- Communication-Efficient Triangle Counting under Local Differential Privacy. **[Topic: DP]**
  [[pdf]](https://www.usenix.org/system/files/sec22-imola.pdf)
  - Jacob Imola, Takao Murakami, Kamalika Chaudhuri. *USENIX Security*, 2022. 

- Security Analysis of Camera-LiDAR Fusion Against Black-Box Attacks on Autonomous Vehicles. **[Topic: AEs & AV]**
  [[pdf]](https://www.usenix.org/system/files/sec22-hallyburton.pdf)
  - R. Spencer Hallyburton, Yupei Liu, Yulong Cao, Z. Morley Mao, Miroslav Pajic. *USENIX Security*, 2022. 

- Transferring Adversarial Robustness Through Robust Representation Matching. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec22-vaishnavi.pdf)
  - Pratik Vaishnavi, Kevin Eykholt, Amir Rahmati. *USENIX Security*, 2022. 

- Seeing is Living? Rethinking the Security of Facial Liveness Verification in the Deepfake Era. **[Topic: Deepfake]**
  [[pdf]](https://www.usenix.org/system/files/sec22-li-changjiang.pdf)
  - Changjiang Li, Li Wang, Shouling Ji, Xuhong Zhang, Zhaohan Xi, Shanqing Guo, Ting Wang. *USENIX Security*, 2022. 

- On the Necessity of Auditable Algorithmic Definitions for Machine Unlearning. **[Topic: Machine-Unlearning]**
  [[pdf]](https://www.usenix.org/system/files/sec22-thudi.pdf)
  - Anvith Thudi, Hengrui Jia, Ilia Shumailov, Nicolas Papernot. *USENIX Security*, 2022. 

- Mitigating Membership Inference Attacks by Self-Distillation Through a Novel Ensemble Architecture. **[Topic: MIA]**
  [[pdf]](https://www.usenix.org/system/files/sec22-tang.pdf)
  - Xinyu Tang, Saeed Mahloujifar, Liwei Song, Virat Shejwalkar, Milad Nasr, Amir Houmansadr, Prateek Mittal. *USENIX Security*, 2022. 

- Membership Inference Attacks and Defenses in Neural Network Pruning. **[Topic: MIA]**
  [[pdf]](https://www.usenix.org/system/files/sec22-yuan-xiaoyong.pdf)
  - Xiaoyong Yuan, Lan Zhang. *USENIX Security*, 2022. 

- Efficient Differentially Private Secure Aggregation for Federated Learning via Hardness of Learning with Errors. **[Topic: DP & FL]**
  [[pdf]](https://www.usenix.org/system/files/sec22-stevens.pdf)
  - Timothy Stevens, Christian Skalka, Christelle Vincent, John Ring, Samuel Clark, Joseph Near. *USENIX Security*, 2022. 

- Who Are You (I Really Wanna Know)? Detecting Audio DeepFakes Through Vocal Tract Reconstruction. **[Topic: Deepfake]**
  [[pdf]](https://www.usenix.org/system/files/sec22-blue.pdf)
  - Logan Blue, Kevin Warren, Hadi Abdullah, Cassidy Gibson, Luis Vargas, Jessica O'Dell, Kevin Butler, Patrick Traynor. *USENIX Security*, 2022. 


- Are Your Sensitive Attributes Private? Novel Model Inversion Attribute Inference Attacks on Classification Models. **[Topic: MIAI]**
  [[pdf]](hhttps://www.usenix.org/system/files/sec22-mehnaz.pdf)
  - Shagufta Mehnaz, Sayanton V. Dibbo, Ehsanul Kabir, Ninghui Li, Elisa Bertino. *USENIX Security*, 2022. 

- FLAME: Taming Backdoors in Federated Learning. **[Topic: FL & Backdoor]**
  [[pdf]](https://www.usenix.org/system/files/sec22-nguyen.pdf)
  - Thien Duc Nguyen, Phillip Rieger, Huili Chen, Hossein Yalame, Helen Möllering, Hossein Fereidooni, Samuel Marchal, Markus Miettinen, Azalia Mirhoseini, Shaza Zeitouni, Farinaz Koushanfar, Ahmad-Reza Sadeghi, Thomas Schneider. *USENIX Security*, 2022. 

- Synthetic Data – Anonymisation Groundhog Day. **[Topic: Synthetic-Data]**
  [[pdf]](https://www.usenix.org/system/files/sec22-stadler.pdf)
  - Theresa Stadler, Bristena Oprisanu, Carmela Troncoso. *USENIX Security*, 2022. 

- On the Security Risks of AutoML. **[Topic: NAS]**
  [[pdf]](https://www.usenix.org/system/files/sec22-pang-ren.pdf)
  - Ren Pang, Zhaohan Xi, Shouling Ji, Xiapu Luo, Ting Wang. *USENIX Security*, 2022. 

- Inference Attacks Against Graph Neural Networks. **[Topic: IA & GNN]**
  [[pdf]](https://www.usenix.org/system/files/sec22-zhang-zhikun.pdf)
  - Zhikun Zhang, Min Chen, Michael Backes, Yun Shen, Yang Zhang. *USENIX Security*, 2022. 

- Adversarial Detection Avoidance Attacks: Evaluating the robustness of perceptual hashing-based client-side scanning. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec22-jain.pdf)
  - Shubham Jain, Ana-Maria Crețu, Yves-Alexandre de Montjoye. *USENIX Security*, 2022. 

- Label Inference Attacks Against Vertical Federated Learning. **[Topic: IA & FL]**
  [[pdf]](https://www.usenix.org/system/files/sec22-fu-chong.pdf)
  - Chong Fu, Xuhong Zhang, Shouling Ji, Jinyin Chen, Jingzheng Wu, Shanqing Guo, Jun Zhou, Alex X. Liu, Ting Wang. *USENIX Security*, 2022. 

- Rolling Colors: Adversarial Laser Exploits against Traffic Light Recognition. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec22-yan.pdf)
  - Chen Yan, Zhijian Xu, Zhanyuan Yin, Xiaoyu Ji, Wenyuan Xu. *USENIX Security*, 2022. 


### USENIX Security '2021

- PatchGuard: A Provably Robust Defense against Adversarial Patches via Small Receptive Fields and Masking. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec21-xiang.pdf)
  - Chong Xiang, Arjun Nitin Bhagoji, Vikash Sehwag, Prateek Mittal. *USENIX Security*, 2021. 

- PrivSyn: Differentially Private Data Synthesis. **[Topic: DP]**
  [[pdf]](https://www.usenix.org/system/files/sec21-zhang-zhikun.pdf)
  - Zhikun Zhang, Tianhao Wang, Ninghui Li, Jean Honorio, Michael Backes, Shibo He, Jiming Chen, Yang Zhang. *USENIX Security*, 2021. 

- Muse: Secure Inference Resilient to Malicious Clients. **[Topic: IA]**
  [[pdf]](https://www.usenix.org/system/files/sec21-lehmkuhl.pdf)
  - Ryan Lehmkuhl, Pratyush Mishra, Akshayaram Srinivasan, Raluca Ada Popa. *USENIX Security*, 2021. 

- Systematic Evaluation of Privacy Risks of Machine Learning Models. **[Topic: IA]**
  [[pdf]](https://www.usenix.org/system/files/sec21-song.pdf)
  - Liwei Song, Prateek Mittal. *USENIX Security*, 2021. 

- Explanation-Guided Backdoor Poisoning Attacks Against Malware Classifiers. **[Topic: Backdoor]**
  [[pdf]](https://www.usenix.org/system/files/sec21-severi.pdf)
  - Giorgio Severi, Jim Meyer, Scott Coull, Alina Oprea. *USENIX Security*, 2021. 

- Cerebro: A Platform for Multi-Party Cryptographic Collaborative Learning. **[Topic: MPC]**
  [[pdf]](https://www.usenix.org/system/files/sec21-zheng.pdf)
  - Wenting Zheng, Ryan Deng, Weikeng Chen, Raluca Ada Popa, Aurojit Panda, Ion Stoica. *USENIX Security*, 2021. 

- T-Miner: A Generative Approach to Defend Against Trojan Attacks on DNN-based Text Classification. **[Topic: Backdoor]**
  [[pdf]](https://www.usenix.org/system/files/sec21-azizi.pdf)
  - Ahmadreza Azizi, Ibrahim Asadullah Tahmid, Asim Waheed, Neal Mangaokar, Jiameng Pu, Mobin Javed, Chandan K. Reddy, Bimal Viswanath, Virginia Tech. *USENIX Security*, 2021. 

- Defeating DNN-Based Traffic Analysis Systems in Real-Time With Blind Adversarial Perturbations. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec21-nasr.pdf)
  - Milad Nasr, Alireza Bahramali, Amir Houmansadr. *USENIX Security*, 2021. 

- Data Poisoning Attacks to Local Differential Privacy Protocols. **[Topic: PA & DP]**
  [[pdf]](https://www.usenix.org/system/files/sec21-cao-xiaoyu.pdf)
  - Xiaoyu Cao, Jinyuan Jia, Neil Zhenqiang Gong. *USENIX Security*, 2021. 

- How to Make Private Distributed Cardinality Estimation Practical, and Get Differential Privacy for Free. **[Topic: DP]**
  [[pdf]](https://www.usenix.org/conference/usenixsecurity21/presentation/hu-changhui)
  - Changhui Hu, Jin Li, Zheli Liu, Xiaojie Guo, Yu Wei, and Xuan Guang, Grigorios Loukides, Changyu Dong. *USENIX Security*, 2021. 

- SLAP: Improving Physical Adversarial Examples with Short-Lived Adversarial Perturbations. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec21-lovisotto.pdf)
  - Giulio Lovisotto, Henry Turner, Ivo Sluganovic, Martin Strohmeier, Ivan Martinovic. *USENIX Security*, 2021. 

- WaveGuard: Understanding and Mitigating Audio Adversarial Examples. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec21-hussain.pdf)
  - Shehzeen Hussain, Paarth Neekhara, Shlomo Dubnov, Julian McAuley, Farinaz Koushanfar. *USENIX Security*, 2021. 

- Graph Backdoor. **[Topic: Backdoor]**
  [[pdf]](https://www.usenix.org/system/files/sec21-xi.pdf)
  - Zhaohan Xi, Ren Pang, Shouling Ji, Ting Wang. *USENIX Security*, 2021. 

- Entangled Watermarks as a Defense against Model Extraction. **[Topic: Watermark]**
  [[pdf]](https://www.usenix.org/system/files/sec21-jia.pdf)
  - Hengrui Jia, Christopher A. Choquette-Choo, Varun Chandrasekaran, Nicolas Papernot. *USENIX Security*, 2021. 

- Too Good to Be Safe: Tricking Lane Detection in Autonomous Driving with Crafted Perturbations. **[Topic: AEs]**
  [[pdf]](https://www.usenix.org/system/files/sec21-jing.pdf)
  - Pengfei Jing, Qiyi Tang, Yuefeng Du,  Lei Xue, Xiapu Luo, Ting Wang, Sen Nie, Shi Wu. *USENIX Security*, 2021. 

- Fantastic Four: Honest-Majority Four-Party Secure Computation With Malicious Security. **[Topic: MPC]**
  [[pdf]](https://www.usenix.org/system/files/sec21-dalskov.pdf)
  - Anders Dalskov, Daniel Escudero, Marcel Keller. *USENIX Security*, 2021. 

- Locally Differentially Private Analysis of Graph Statistics. **[Topic: DP]**
  [[pdf]](https://www.usenix.org/system/files/sec21-imola.pdf)
  - Jacob Imola, Takao Murakami, Kamalika Chaudhuri. *USENIX Security*, 2021. 

- Demon in the Variant: Statistical Analysis of DNNs for Robust Backdoor Contamination Detection. **[Topic: Backdoor]**
  [[pdf]](https://www.usenix.org/system/files/sec21-tang-di.pdf)
  - Di Tang, XiaoFeng Wang, Haixu Tang, Kehuan Zhang. *USENIX Security*, 2021. 

- Stealing Links from Graph Neural Networks. **[Topic: GNN]**
  [[pdf]](https://www.usenix.org/system/files/sec21-he-xinlei.pdf)
  - Xinlei He, Jinyuan Jia, Michael Backes, Neil Zhenqiang Gong, Yang Zhang. *USENIX Security*, 2021. 

- Adversarial Policy Training against Deep Reinforcement Learning. **[Topic: AEs & RL]**
  [[pdf]](https://www.usenix.org/system/files/sec21-wu-xian.pdf)
  - Xian Wu, Wenbo Guo, Hua Wei, Xinyu Xing. *USENIX Security*, 2021. 

## Papers in CCS
### CCS '2024
- Moderator: Moderating Text-to-Image Diffusion Models through Fine-grained Context-based Policies. **[Topic: ML and Security: Large Language Models]**
  [[pdf]](https://arxiv.org/abs/2408.07728)
  - Peiran Wang, Qiyu Li, Longxuan Yu, Ziyao Wang, Ang Li, Haojian Jin. *ACM CCS*, 2024.

- Training Robust ML-based Raw-Binary Malware Detectors in Hours, not Months. **[Topic: Verification, Secure Architectures, and Network Security]**
  [[pdf]](https://doi.org/10.1145/3658644.3690208)
  - Keane Lucas, Weiran Lin, Lujo Bauer, Michael K. Reiter, Mahmood Sharif. *ACM CCS*, 2024.

- TREC: APT Tactic / Technique Recognition via Few-Shot Provenance Subgraph Learning. **[Topic: Verification, Secure Architectures, and Network Security]**
  [[pdf]](https://arxiv.org/abs/2402.15147)
  - Mingqi Lv, HongZhe Gao, Xuebo Qiu, Tieming Chen, Tiantian Zhu, Jinyin Chen, Shouling Ji. *ACM CCS*, 2024.

- SAFARI: Speech-Associated Facial Authentication for AR/VR Settings via Robust VIbration Signatures **[Topic: Verification, Secure Architectures, and Network Security]**
  [[pdf]](https://doi.org/10.1145/3658644.3670358)
  - Tianfang Zhang, Qiufan Ji, Zhengkun Ye, Md Mojibur Rahman Redoy Akanda, Ahmed Tanvir Mahdad, Cong Shi, Yan Wang, Nitesh Saxena, Yingying Chen. *ACM CCS*, 2024.

- KnowGraph: Knowledge-Enabled Anomaly Detection via Logical Reasoning on Graph Data. **[Topic: Verification, Secure Architectures, and Network Security]**
  [[pdf]](https://arxiv.org/abs/2410.08390)
  -Andy Zhou, Xiaojun Xu, Ramesh Raghunathan, Alok Lal, Xinze Guan, Bin Yu, Bo Li. *ACM CCS*, 2024.

- Understanding Implosion in Text-to-Image Generative Models. **[Topic: ML and Security: Large Language Models]**
  [[pdf]](https://arxiv.org/abs/2409.12314)
  - Wenxin Ding, Cathy Y. Li, Shawn Shan, Ben Y. Zhao, Haitao Zheng. *ACM CCS*, 2024.

- Legilimens: Practical and Unified Content Moderation for Large Language Model Services. **[Topic: ML and Security: Large Language Models]**
  [[pdf]](https://arxiv.org/abs/2408.15488)
  - Jialin Wu, Jiangyi Deng, Shengyuan Pang, Yanjiao Chen, Jiayang Xu, Xinfeng Li, Wenyuan Xu. *ACM CCS*, 2024.

- Optimization-based Prompt Injection Attack to LLM-as-a-Judge. **[Topic: ML and Security: Machine Learning Attacks]**
  [[pdf]](https://arxiv.org/abs/2403.17710)
  - Jiawen Shi, Zenghui Yuan, Yinuo Liu, Yue Huang, Pan Zhou, Lichao Sun, Neil Zhenqiang Gong. *ACM CCS*, 2024.

- PromSec: Prompt Optimization for Secure Generation of Functional Source Code with Large Language Models (LLMs). **[Topic: ML and Security: Generative Models]**
  [[pdf]](https://arxiv.org/abs/2409.12699)
  - Mahmoud Nazzal, Issa Khalil, Abdallah Khreishah, NhatHai Phan. *ACM CCS*, 2024.ML and Security: Machine Learning Attacks

- Certifiable Black-Box Attacks with Randomized Adversarial Examples: Breaking Defenses with Provable Confidence **[Topic: ML and Security: Machine Learning Attacks]**
  [[pdf]](https://arxiv.org/abs/2304.04343)
  - Hanbin Hong, Xinyu Zhang, Binghui Wang, Zhongjie Ba, Yuan Hong. *ACM CCS*, 2024.

- Phantom: Untargeted Poisoning Attacks on Semi-Supervised Learning (Full Version) **[Topic: ML and Security: Machine Learning Attacks]**
  [[pdf]](https://arxiv.org/abs/2409.01470)
  - Jonathan Knauer, Phillip Rieger, Hossein Fereidooni, Ahmad-Reza Sadeghi. *ACM CCS*, 2024.

- Zero-Query Adversarial Attack on Black-box Automatic Speech Recognition Systems **[Topic: ML and Security: Machine Learning Attacks]**
  [[pdf]](https://arxiv.org/abs/2406.19311)
  - Zheng Fang, Tao Wang, Lingchen Zhao, Shenyi Zhang, Bowen Li, Yunjie Ge, Qi Li, Chao Shen, Qian Wang. *ACM CCS*, 2024.

- SUB-PLAY: Adversarial Policies against Partially Observed Multi-Agent Reinforcement Learning Systems **[Topic: ML and Security: Machine Learning Attacks]**
  [[pdf]](https://arxiv.org/abs/2402.03741)
  - Oubo Ma, Yuwen Pu, Linkang Du, Yang Dai, Ruo Wang, Xiaolei Liu, Yingcai Wu, Shouling Ji. *ACM CCS*, 2024.

- Optimization-based Prompt Injection Attack to LLM-as-a-Judge **[Topic: ML and Security: Machine Learning Attacks]**
  [[pdf]](https://arxiv.org/abs/2403.17710)
  - Jiawen Shi, Zenghui Yuan, Yinuo Liu, Yue Huang, Pan Zhou, Lichao Sun, Neil Zhenqiang Gong. *ACM CCS*, 2024.

- Neural Dehydration: Effective Erasure of Black-box Watermarks from DNNs with Limited Data **[Topic: ML and Security: Machine Learning Attacks]**
  [[pdf]](https://arxiv.org/abs/2309.03466)
  - Yifan Lu, Wenxuan Li, Mi Zhang, Xudong Pan, Min Yang. *ACM CCS*, 2024.

- Is Difficulty Calibration All We Need? Towards More Practical Membership Inference Attacks **[Topic: Blockchain & Distributed Systems: Blockchain Attacks]**
  [[pdf]](https://arxiv.org/abs/2409.00426)
  - Yu He, Boheng Li, Yao Wang, Mengda Yang, Juan Wang, Hongxin Hu, Xingyu Zhao. *ACM CCS*, 2024.

- Evaluations of Machine Learning Privacy Defenses are Misleading **[Topic: Blockchain & Distributed Systems: Blockchain Attacks]**
  [[pdf]](https://arxiv.org/abs/2404.17399)
  - Michael Aerni, Jie Zhang, Florian Tramèr. *ACM CCS*, 2024.

- A Unified Membership Inference Method for Visual Self-supervised Encoder via Part-aware Capability **[Topic: Blockchain & Distributed Systems: Blockchain Attacks]**
  [[pdf]](https://arxiv.org/abs/2404.02462)
  - Jie Zhu, Jirong Zha, Ding Li, Leye Wang. *ACM CCS*, 2024.

- The Janus Interface: How Fine-Tuning in Large Language Models Amplifies the Privacy Risks **[Topic: Blockchain & Distributed Systems: Blockchain Attacks]**
  [[pdf]](https://arxiv.org/abs/2310.15469)
  - Xiaoyi Chen, Siyuan Tang, Rui Zhu, Shijun Yan, Lei Jin, Zihao Wang, Liya Su, Zhikun Zhang, XiaoFeng Wang, Haixu Tang. *ACM CCS*, 2024.

- A General Framework for Data-Use Auditing of ML Models **[Topic: Blockchain & Distributed Systems: Blockchain Attacks]**
  [[pdf]](https://arxiv.org/abs/2407.15100)
  - Zonghao Huang, Neil Zhenqiang Gong, Michael K. Reiter. *ACM CCS*, 2024.

- Dye4AI: Assuring Data Boundary on Generative AI Services **[Topic: ML and Security: Generative Models]**
  [[pdf]](https://arxiv.org/abs/2406.14114)
  - Shu Wang, Kun Sun, Yan Zhai. *ACM CCS*, 2024.

- I Don't Know You, But I Can Catch You: Real-Time Defense against Diverse Adversarial Patches for Object Detectors **[Topic:  Privacy and Anonymity: Privacy Attacks Meet ML]**
  [[pdf]](https://arxiv.org/abs/2406.10285)
  - Zijin Lin, Yue Zhao, Kai Chen, Jinwen He. *ACM CCS*, 2024.

- AirGapAgent: Protecting Privacy-Conscious Conversational Agents **[Topic:  Privacy and Anonymity: Privacy Attacks Meet ML]**
  [[pdf]](https://arxiv.org/abs/2405.05175)
  - Eugene Bagdasarian, Ren Yi, Sahra Ghalebikesabi, Peter Kairouz, Marco Gruteser, Sewoong Oh, Borja Balle, Daniel Ramage. *ACM CCS*, 2024.

- ERASER: Machine Unlearning in MLaaS via an Inference Serving-Aware Approach **[Topic:  Privacy and Anonymity: Privacy Attacks Meet ML]**
  [[pdf]](https://arxiv.org/abs/2311.16136)
  - Yuke Hu, Jian Lou, Jiaqi Liu, Wangze Ni, Feng Lin, Zhan Qin, Kui Ren. *ACM CCS*, 2024.

- NeuJeans: Private Neural Network Inference with Joint Optimization of Convolution and FHE Bootstrapping **[Topic:  Usability and Measurement: Phishing, Deepfakes, and Other Risks]**
  [[pdf]](https://arxiv.org/abs/2312.04356)
  - Jae Hyung Ju, Jaiyoung Park, Jongmin Kim, Minsik Kang, Donghwan Kim, Jung Hee Cheon, Jung Ho Ahn. *ACM CCS*, 2024.

- Ents: An Efficient Three-party Training Framework for Decision Trees by Communication Optimization **[Topic:  Usability and Measurement: Phishing, Deepfakes, and Other Risks]**
  [[pdf]](https://arxiv.org/abs/2406.07948)
  - Guopeng Lin, Weili Han, Wenqiang Ruan, Ruisheng Zhou, Lushan Song, Bingshuai Li, Yunfeng Shao. *ACM CCS*, 2024.

- zkLLM: Zero Knowledge Proofs for Large Language Models **[Topic:  Usability and Measurement: Phishing, Deepfakes, and Other Risks]**
  [[pdf]](https://arxiv.org/abs/2404.16109)
  - Haochen Sun, Jason Li, Hongyang Zhang. *ACM CCS*, 2024.

- Fisher Information guided Purification against Backdoor Attacks **[Topic:  ML and Security: Model Security]**
  [[pdf]](https://arxiv.org/abs/2409.00863)
  - Nazmul Karim, Abdullah Al Arafat, Adnan Siraj Rakin, Zhishan Guo, Nazanin Rahnavard. *ACM CCS*, 2024.

- BadMerging: Backdoor Attacks Against Model Merging **[Topic:  ML and Security: Model Security]**
  [[pdf]](https://arxiv.org/abs/2408.07362)
  - Jinghuai Zhang, Jianfeng Chi, Zheng Li, Kunlin Cai, Yang Zhang, Yuan Tian. *ACM CCS*, 2024.

- SafeGen: Mitigating Sexually Explicit Content Generation in Text-to-Image Models **[Topic:  Usability and Measurement: AI Risks]**
  [[pdf]](https://arxiv.org/abs/2404.06666)
  - Xinfeng Li, Yuchen Yang, Jiangyi Deng, Chen Yan, Yanjiao Chen, Xiaoyu Ji, Wenyuan Xu. *ACM CCS*, 2024.

- Image-Perfect Imperfections: Safety, Bias, and Authenticity in the Shadow of Text-To-Image Model Evolution **[Topic:  Usability and Measurement: AI Risks]**
  [[pdf]](https://arxiv.org/abs/2408.17285)
  - Yixin Wu, Yun Shen, Michael Backes, Yang Zhang. *ACM CCS*, 2024.

### CCS '2023
- Decoding the Secrets of Machine Learning in Malware Classification: A Deep Dive into Datasets, Feature Extraction, and Model Performance **[Topic:  Machine Learning Applications I]**
  [[pdf]](https://arxiv.org/abs/2307.14657)
  - Savino Dambra, Yufei Han, Simone Aonzo, Platon Kotzias, Antonino Vitale, Juan Caballero, Davide Balzarotti, Leyla Bilge. *ACM CCS*, 2023.

- Efficient Query-Based Attack against ML-Based Android Malware Detection under Zero Knowledge Setting **[Topic:  Machine Learning Applications I]**
  [[pdf]](https://arxiv.org/abs/2309.01866)
  - Ping He, Yifan Xia, Xuhong Zhang, Shouling Ji. *ACM CCS*, 2023.

- Your Battery Is a Blast! Safeguarding Against Counterfeit Batteries with Authentication **[Topic:  Machine Learning Applications I]**
  [[pdf]](https://arxiv.org/abs/2309.03607)
  - Francesco Marchiori, Mauro Conti. *ACM CCS*, 2023.

- Narcissus: A Practical Clean-Label Backdoor Attack with Limited Information **[Topic: Machine Learning Attacks I]**
  [[pdf]](https://arxiv.org/abs/2204.05255)
  - Yi Zeng, Minzhou Pan, Hoang Anh Just, Lingjuan Lyu, Meikang Qiu, Ruoxi Jia. *ACM CCS*, 2023.

- Stateful Defenses for Machine Learning Models Are Not Yet Secure Against Black-box Attacks **[Topic: Machine Learning Attacks I]**
  [[pdf]](https://arxiv.org/abs/2303.06280)
  - Ryan Feng, Ashish Hooda, Neal Mangaokar, Kassem Fawaz, Somesh Jha, Atul Prakash. *ACM CCS*, 2023.

- Evading Watermark based Detection of AI-Generated Content **[Topic: Machine Learning Attacks II]**
  [[pdf]](https://arxiv.org/abs/2305.03807)
  - Zhengyuan Jiang, Jinghuai Zhang, Neil Zhenqiang Gong. *ACM CCS*, 2023.

- Verifiable Learning for Robust Tree Ensembless **[Topic: Language Models & Verification]**
  [[pdf]](https://arxiv.org/abs/2305.03626)
  - Stefano Calzavara, Lorenzo Cazzaro, Giulio Ermanno Pibiri, Nicola Prezza. *ACM CCS*, 2023.

- Large Language Models for Code: Security Hardening and Adversarial Testing **[Topic: Language Models & Verification]**
  [[pdf]](https://arxiv.org/abs/2302.05319)
  - Jingxuan He, Martin Vechev. *ACM CCS*, 2023.
### CCS '2022
- Characterizing and Detecting Non-Consensual Photo Sharing on Social Networks. **[Topic: Non-consensual Sharing]**
  [[pdf]](https://dl.acm.org/doi/10.1145/3548606.3560571)
  - Tengfei Zheng, Tongqing Zhou, Qiang Liu, Kui Wu, Zhiping Cai. *ACM CCS*, 2022.

- DPIS: An Enhanced Mechanism for Differentially Private SGD with Importance Sampling. **[Topic: DP & DNN]**
  [[pdf]](https://arxiv.org/abs/2210.09634)
  - Jianxin Wei, Ergute Bao, Xiaokui Xiao, Yin Yang. *ACM CCS*, 2022.

- DriveFuzz: Discovering Autonomous Driving Bugs through Driving Quality-Guided Fuzzing. **[Topic: AD]**
  [[pdf]](https://arxiv.org/abs/2211.01829)
  - Seulbae Kim, Major Liu, Junghwan "John" Rhee, Yuseok Jeon, Yonghwi Kwon, Chung Hwan Kim. *ACM CCS*, 2022.

- EIFFeL: Ensuring Integrity for Federated Learning. **[Topic: FL]**
  [[pdf]](https://arxiv.org/abs/2112.12727)
  - Amrita Roy Chowdhury, Chuan Guo, Somesh Jha, Laurens van der Maaten. *ACM CCS*, 2022.

- Eluding Secure Aggregation in Federated Learning via Model Inconsistency. **[Topic: FL]**
  [[pdf]](https://dl.acm.org/doi/10.1145/3548606.3560557)
  - Dario Pasquini, Danilo Francati, Giuseppe Ateniese. *ACM CCS*, 2022.

- Enhanced Membership Inference Attacks against Machine Learning Models. **[Topic: MI]**
  [[pdf]](https://dl.acm.org/doi/10.1145/3548606.3560675)
  - Jiayuan Ye, Aadyaa Maddi, Sasi Kumar Murakonda, Vincent Bindschaedler, Reza Shokri. *ACM CCS*, 2022.

- Feature Inference Attack on Shapley Values. **[Topic: MLaaS]**
  [[pdf]](https://dl.acm.org/doi/pdf/10.1145/3548606.3560573)
  - Xinjian Luo, Yangfan Jiang, Xiaokui Xiao. *ACM CCS*, 2022.

- Graph Unlearning. **[Topic: Machine Unlearning]**
  [[pdf]](https://arxiv.org/abs/2103.14991)
  - Min Chen, Zhikun Zhang, Tianhao Wang, Michael Backes, Mathias Humbert, Yang Zhang. *ACM CCS*, 2022.

- Group Property Inference Attacks Against Graph Neural Networks. **[Topic: GNNs]**
  [[pdf]](https://dl.acm.org/doi/10.1145/3548606.3560662)
  - Xiuling Wang, Wendy Hui Wang. *ACM CCS*, 2022.

- Harnessing Perceptual Adversarial Patches for Crowd Counting. **[Topic: AEs]**
  [[pdf]](https://dl.acm.org/doi/10.1145/3548606.3560566)
  - Shunchang Liu, Jiakai Wang, Aishan Liu, Yingwei Li, Yijie Gao, Xianglong Liu, Dacheng Tao. *ACM CCS*, 2022.

- Training Set Debugging Using Trusted Items. **[Topic: ML]**
  [[pdf]](https://arxiv.org/abs/1801.08019)
  - Zayd Hammoudeh, Daniel Lowd. *ACM CCS*, 2022.

- LPGNet: Link Private Graph Networks for Node Classification. **[Topic: GCNs & DP]**
  [[pdf]](https://arxiv.org/abs/2205.03105)
  - Aashish Kolluri, Teodora Baluta, Bryan Hooi, Prateek Saxena. *ACM CCS*, 2022.

- LoneNeuron: a Highly-Effective Feature-Domain Neural Trojan Using Invisible and Polymorphic Watermarks. **[Topic: DNNs & Watermark]**
  [[pdf]](https://dl.acm.org/doi/pdf/10.1145/3548606.3560678)
  - Zeyan Liu, Fengjun Li, Zhu Li, Bo Luo. *ACM CCS*, 2022.

- Membership Inference Attacks and Generalization: A Causal Perspective. **[Topic: MI]**
  [[pdf]](https://arxiv.org/abs/2209.08615)
  - Teodora Baluta, Shiqi Shen, S. Hitarth, Shruti Tople, Prateek Saxena. *ACM CCS*, 2022.

- Membership Inference Attacks by Exploiting Loss Trajectory. **[Topic: MI]**
  [[pdf]](https://dl.acm.org/doi/10.1145/3548606.3560684)
  - Yiyong Liu, Zhengyu Zhao, Michael Backes, Yang Zhang. *ACM CCS*, 2022.

- Order-Disorder: Imitation Adversarial Attacks for Black-box Neural Ranking Models. **[Topic: IR]**
  [[pdf]](https://arxiv.org/abs/2209.06506)
  - Jiawei Liu, Yangyang Kang, Di Tang, Kaisong Song, Changlong Sun, Xiaofeng Wang, Wei Lu, Xiaozhong Liu. *ACM CCS*, 2022.

- Perception-Aware Attack: Creating Adversarial Music via Reverse-Engineering Human Perception. **[Topic: AEs]**
  [[pdf]](https://arxiv.org/abs/2207.13192)
  - Rui Duan, Zhe Qu, Shangqing Zhao, Leah Ding, Yao Liu, Zhuo Lu. *ACM CCS*, 2022.

- Physical Hijacking Attacks against Object Trackers. **[Topic: AV]**
  [[pdf]](https://dl.acm.org/doi/10.1145/3548606.3559390)
  - Raymond Muller, Yanmao Man, Z. Berkay Celik, Ming Li, Ryan Gerdes. *ACM CCS*, 2022.

- Post-breach Recovery: Protection against White-box Adversarial Examples for Leaked DNN Models. **[Topic: DNN]**
  [[pdf]](https://dl.acm.org/doi/10.1145/3548606.3560561)
  - Shawn Shan, Wenxin Ding, Emily Wenger, Haitao Zheng, Ben Y. Zhao. *ACM CCS*, 2022.

- QuerySnout: Automating the Discovery of Attribute Inference Attacks against Query-Based Systems. **[Topic: QBS]**
  [[pdf]](https://arxiv.org/abs/2211.05249)
  - Ana-Maria Crețu, Florimond Houssiau, Antoine Cully, Yves-Alexandre de Montjoye. *ACM CCS*, 2022.

- SSLGuard: A Watermarking Scheme for Self-supervised Learning Pre-trained Encoders. **[Topic: Watermark]**
  [[pdf]](https://arxiv.org/abs/2201.11692)
  - Tianshuo Cong, Xinlei He, Yang Zhang. *ACM CCS*, 2022.

- SpecPatch: Human-In-The-Loop Adversarial Audio Spectrogram Patch Attack on Speech Recognition. **[Topic: AEs]**
  [[pdf]](https://doi.org/10.1145/3548606.3560660)
  - Hanqing Guo, Yuanda Wang, Nikolay Ivanov, Li Xiao, Qiben Yan. *ACM CCS*, 2022.

- StolenEncoder: Stealing Pre-trained Encoders in Self-supervised Learning. **[Topic: EaaS]**
  [[pdf]](https://dl.acm.org/doi/10.1145/3548606.3560586)
  - Yupei Liu, Jinyuan Jia, Hongbin Liu, Neil Gong. *ACM CCS*, 2022.

- Truth Serum: Poisoning Machine Learning Models to Reveal Their Secrets. **[Topic: ML]**
  [[pdf]](https://arxiv.org/abs/2204.00032)
  - Florian Tramer, Reza Shokri, Ayrton San Joaquin, Hoang Le, Matthew Jagielski, Sanghyun Hong, Nicholas Carlini. *ACM CCS*, 2022.

- Understanding Real-world Threats to Deep Learning Models in Android Apps. **[Topic: AEs]**
  [[pdf]](https://dl.acm.org/doi/10.1145/3548606.3559388)
  - Zizhuang Deng, Kai Chen, Guozhu Meng, Xiaodong Zhang, Ke Xu, Yao Cheng. *ACM CCS*, 2022.

- When Evil Calls: Targeted Adversarial Voice over IP Network. **[Topic: AEs]**
  [[pdf]](https://dl.acm.org/doi/10.1145/3548606.3560671)
  - Han Liu, Zhiyuan Yu, Mingming Zha, XiaoFeng Wang, William Yeoh, Yevgeniy Vorobeychik, Ning Zhang. *ACM CCS*, 2022.

- Why So Toxic? Measuring and Triggering Toxic Behavior in Open-Domain Chatbots. **[Topic: AEs]**
  [[pdf]](https://arxiv.org/abs/2209.03463)
  - Wai Man Si, Michael Backes, Jeremy Blackburn, Emiliano De Cristofaro, Gianluca Stringhini, Savvas Zannettou, Yang Zhang. *ACM CCS*, 2022.

- "Is your explanation stable?": A Robustness Evaluation Framework for Feature Attribution. **[Topic: NNs]**
  [[pdf]](https://arxiv.org/abs/2209.01782v1)
  - Yuyou Gan, Yuhao Mao, Xuhong Zhang, Shouling Ji, Yuwen Pu, Meng Han, Jianwei Yin, Ting Wang. *ACM CCS*, 2022.


### CCS '2021

- Cert-RNN: Towards Certifying the Robustness of Recurrent Neural Networks. **[Topic: AEs]**
  [[pdf]](https://nesa.zju.edu.cn/download/dty_pdf_cert_rnn.pdf)
  - Tianyu Du, Shouling Ji, Lujia Shen, Yao Zhang, Jinfeng Li, Jie Shi, Chengfang Fang, Jianwei Yin, Raheem Beyah, Ting Wang. *ACM CCS*, 2021.

- AHEAD: Adaptive Hierarchical Decomposition for Range Query under Local Differential Privacy. **[Topic: LDP]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3485668)
  - Linkang Du, Zhikun Zhang, Shaojie Bai, Changchang Liu, Shouling Ji, Peng Cheng, Jiming Chen. *ACM CCS*, 2021.

- Unleashing the Tiger: Inference Attacks on Split Learning. **[Topic: SL]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3485259)
  - Dario Pasquini, Giuseppe Ateniese, Massimo Bernaschi. *ACM CCS*, 2021.

- TableGAN-MCA: Evaluating Membership Collisions of GAN-Synthesized Tabular Data Releasing. **[Topic: GAN]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3485251)
  - Aoting Hu, Renjie Xie, Zhigang Lu, Aiqun Hu, Minhui Xue. *ACM CCS*, 2021.

- "I need a better description": An Investigation Into User Expectations For Differential Privacy. **[Topic: DP]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3485252)
  - Rachel Cummings, Gabriel Kaptchuk, Elissa M. Redmiles. *ACM CCS*, 2021.

- Locally Private Graph Neural Networks. **[Topic: GNNs]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3484565)
  - Sina Sajadmanesh, Daniel Gatica-Perez. *ACM CCS*, 2021.

- A One-Pass Distributed and Private Sketch for Kernel Sums with Applications to Machine Learning at Scale. **[Topic: DP]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3485255)
  - Benjamin Coleman, Anshumali Shrivastava. *ACM CCS*, 2021.

- On the Robustness of Domain Constraints. **[Topic: AEs]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3484570)
  - Ryan Sheatsley, Blaine Hoak, Eric Pauley, Yohan Beugin, Michael J. Weisman,  Patrick McDaniel. *ACM CCS*, 2021.

- Membership Leakage in Label-Only Exposures. **[Topic: MI]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3484575)
  - Zheng Li, Yang Zhang. *ACM CCS*, 2021.

- Hidden Backdoors in Human-Centric Language Models. **[Topic: Backdoor]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3484576)
  - Shaofeng Li, Hui Liu, Tian Dong, Benjamin Zi Hao Zhao, Minhui Xue, Haojin Zhu, Jialiang Lu. *ACM CCS*, 2021.

- DataLens: Scalable Privacy Preserving Training via Gradient Compression and Aggregation. **[Topic: DP]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3484579)
  - Boxin Wang, Fan Wu, Yunhui Long, Luka Rimanic, Ce Zhang, Bo Li. *ACM CCS*, 2021.
 
- DeepAID: Interpreting and Improving Deep Learning-based Anomaly Detection in Security Applications. **[Topic: DL]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3484589)
  - Dongqi Han, Zhiliang Wang, Wenqi Chen, Ying Zhong, Su Wang, Han Zhang, Jiahai Yang, Xingang Shi, Xia Yin. *ACM CCS*, 2021.

- Honest-but-Curious Nets: Sensitive Attributes of Private Inputs Can Be Secretly Coded into the Classifiers' Outputs. **[Topic: Classifer]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3484533)
  - Mohammad Malekzadeh, Anastasia Borovykh, Deniz Gunduz. *ACM CCS*, 2021.
 
- Differential Privacy for Directional Data. **[Topic: DP]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3484734)
  - Benjamin Weggenmann, Florian Kerschbaum. *ACM CCS*, 2021.
 
- "Hello, It's Me": Deep Learning-based Speech Synthesis Attacks in the Real World. **[Topic: Speech Synthesis Attack]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3484742)
  - Emily Wenge, Max Bronckers, Christian Cianfarani, Jenna Cryan, Angela Sha, Haitao Zheng, Ben Y. Zhao. *ACM CCS*, 2021.
 
- EncoderMI: Membership Inference against Pre-trained Encoders in Contrastive Learning. **[Topic: MI]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3484749)
  - Hongbin Liu, Jinyuan Jia, Wenjie Qu, Neil Gong. *ACM CCS*, 2021.
 
- Subpopulation Data Poisoning Attacks. **[Topic: Poisoning Attack]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3485368)
  - Matthew Jagielski, Giorgio Severi, Niklas Pousette Harger, Alina Oprea. *ACM CCS*, 2021.
 
- Continuous Release of Data Streams under both Centralized and Local Differential Privacy. **[Topic: DP]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3484750)
  - Tianhao Wang, Joann Qiongna Chen, Zhikun Zhang, Dong Su, Yueqiang Cheng, Zhou Li, Ninghui Li, Somesh Jha. *ACM CCS*, 2021.
 
- When Machine Unlearning Jeopardizes Privacy. **[Topic: MI]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3484756)
  - Min Chen, Zhikun Zhang, Tianhao Wang, Michael Backes, Mathias Humbert, Yang Zhang. *ACM CCS*, 2021.

- DetectorGuard: Provably Securing Object Detectors against Localized Patch Hiding Attacks. **[Topic: AEs]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3484757)
  - Chong Xiang, Prateek Mittal. *ACM CCS*, 2021.
 
- I Can See the Light: Attacks on Autonomous Vehicles Using Invisible Lights. **[Topic: AV]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3484766)
  - Wei Wang, Yao Yao, Xin Liu, Xiang Li, Pei Hao, Ting Zhu. *ACM CCS*, 2021.
 
- Backdoor Pre-trained Models Can Transfer to All. **[Topic: Backdoor]**
  [[pdf]](https://arxiv.org/abs/2111.00197)
  - Lujia Shen, Shouling Ji, Xuhong Zhang, Jinfeng Li, Jing Chen, Jie Shi, Chengfang Fang, Jianwei Yin, Ting Wang. *ACM CCS*, 2021.

- Quantifying and Mitigating Privacy Risks of Contrastive Learning. **[Topic: CL]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3484571)
  - Xinlei He, Yang Zhang. *ACM CCS*, 2021.
 
- Membership Inference Attacks Against Recommender Systems. **[Topic: MI]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3484770)
  - Minxing Zhang, Zihan Wang, Yang Zhang, Zhaochun Ren, Pengjie Ren, Zhunmin Chen, Pengfei Hu. *ACM CCS*, 2021.

- Learning Security Classifiers with Verified Global Robustness Properties. **[Topic: Classifier]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3484776)
  - Yizheng Chen, Shiqi Wang, Yue Qin, Xiaojing Liao, Suman Jana, David Wagner. *ACM CCS*, 2021.
 
- Robust Adversarial Attacks Against DNN-Based Wireless Communication Systems. **[Topic: AEs]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3484777)
  - Alireza Bahramali, Milad Nasr, Amir Houmansadr, Dennis Goeckel, Don Towsley. *ACM CCS*, 2021.

- Can We Use Arbitrary Objects to Attack LiDAR Perception in Autonomous Driving? **[Topic: AEs]**
  [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3485377)
  - Yi Zhu, Chenglin Miao, Tianhang Zheng, Foad Hajiaghajani, Lu Su, Chunming Qiao. *ACM CCS*, 2021.
 
- Feature Indistinguishable Attack to Circumvent Trapdoor-enabled Defense. **[Topic: AEs]**
   [[Code]](https://github.com/CGCL-codes/FeatureIndistinguishableAttack)[[pdf]](https://dl.acm.org/doi/10.1145/3460120.3485378)
  - Chaoxiang He, Bin (Benjamin) Zhu, Xiaojing Ma, Hai Jin, Shengshan Hu. *ACM CCS*, 2021.

- A Hard Label Black-box Adversarial Attack Against Graph Neural Networks. **[Topic: AEs & DNN]**
   [[pdf]](https://dl.acm.org/doi/10.1145/3460120.3484796)
  - Jiaming Mu, Binghui Wang, Qi Li, Kun Sun, Mingwei Xu, Zhuotao Liu. *ACM CCS*, 2021.
 
- Reverse Attack: Black-box Attacks on Collaborative Recommendation. **[Topic: CF & Poisoning Attack]**
   [[pdf]](https://dl.acm.org/doi/abs/10.1145/3460120.3484805)
  - Yihe Zhang, Xu Yuan, Jin Li, Jiadong Lou, Li Chen, Nianfeng Tzeng. *ACM CCS*, 2021.

- zkCNN: Zero Knowledge Proofs for Convolutional Neural Network Predictions and Accuracy. **[Topic: CNN]**
   [[pdf]](https://dl.acm.org/doi/10.1145/3460120.3485379)
  - Tianyi Liu, Xiang Xie, Yupeng Zhang. *ACM CCS*, 2021.

- Black-box Adversarial Attacks on Commercial Speech Platforms with Minimal Information. **[Topic: AEs]**
   [[pdf]](https://dl.acm.org/doi/10.1145/3460120.3485383)
  - Baolin Zheng, Peipei Jiang, Qian Wang, Qi Li, Chao Shen, Cong Wang, Yunjie Ge, Qingyang Teng, Shenyi Zhang. *ACM CCS*, 2021.

- AI-Lancet: Locating Error-inducing Neurons to Optimize Neural Networks. **[Topic: DNN]**
   [[pdf]](https://dl.acm.org/doi/10.1145/3460120.3484818)
  - Yue Zhao, Hong Zhu, Kai Chen, Shengzhi Zhang. *ACM CCS*, 2021.
